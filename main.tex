%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[12pt,english]{report}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{babel}
\usepackage{longtable}
\usepackage{float}
\usepackage{calc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
 
\usepackage{comment}
\usepackage{graphicx}
\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}[chapter]
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{UTSAthesis}      
\usepackage{times}            
\usepackage{latexsym}

%Bibliography packages
\usepackage[square]{natbib} % defines citet, citep, ...
\bibpunct{(}{)}{;}{a}{}{,} % to follow the A&A style - 
\newcommand{\aj}{AJ}
\newcommand{\apj}{ApJ}
\newcommand{\apjl}{ApJ}
\newcommand{\apjs}{ApJS}
\newcommand{\aap}{A\&A}
\newcommand{\aaps}{A\&AS}
\newcommand{\mnras}{MNRAS}
\newcommand{\nat}{Nature}
\newcommand{\araa}{ARAA}
\newcommand{\prd}{Phys. Rev. D}
\newcommand{\pasj}{PASJ}
\newcommand{\ETC}{et al.}
\newcommand{\physrep}{Physics Report}
\newcommand{\gca}{GCA}
\newcommand{\pasa}{PASA}
\newcommand{\pasp}{PASP}
\newcommand{\aapr}{A\&A~Rev.}
\newcommand{\apss}{Ap\&SS}
%End of bibliography packages 

%Added by me
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\order}{\ensuremath{\mathcal{O}}}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit, backgrounds}

\linespread{1.2}
% Define block styles for pipeline flowchart
\tikzstyle{decision} = [diamond, draw, fill=green!20, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=10em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw, -latex']
\tikzstyle{cloud} = [draw, ellipse, fill=red!20, node distance=3cm,
    text width=5em, text centered, minimum height=2em]
\tikzstyle{obse} = [draw, rectangle, fill=green!30, node distance=3cm,
    text width=5em, text centered, rounded corners, minimum height=2em]
    
\usepackage{minted}
%End of added by me

\newenvironment{ruledcenter}{%
  \begin{center}
  \rule{\textwidth}{1mm} } {%
  \rule{\textwidth}{1mm} 
  \end{center}}%


  \theoremstyle{definition}
  \newtheorem{defn}{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

\@ifundefined{showcaptionsetup}{}{%
 \PassOptionsToPackage{caption=false}{subfig}}
\usepackage{subfig}
\makeatother

\providecommand{\definitionname}{Definition}
\providecommand{\theoremname}{Theorem}

\begin{document}

% Committee Members
\supervisor{Mario Diaz, Ph.D.}
\committeeB{Lucas Macri, Ph.D.}
\committeeC{Matthew Benacquista, Ph.D.}
\committeeD{Eric Schlegel, Ph.D.}
\committeeE{Ricardo Lopez Mobilia, Ph.D.}

\informationitems{Doctor of Philosophy in Physics}{Ph.D.}{M.Sc.}{Department of Physics And Astronomy}{College of Sciences}{May}{ 2017 }

\thesiscopyright{Copyright 2017 Martin Beroiz \\
All rights reserved. }

\dedication{\emph{I would like to dedicate this thesis to ??????.}}


\title{\textbf{OPTICAL COUNTERPARTS TO GRAVITATIONAL WAVES}}


\author{Martin Beroiz}
\maketitle
\begin{acknowledgements}
Thanks y'all.

(Notice: If any part of the thesis/dissertation has been published
before, the following two paragraphs should be included without alteration).

\begin{singlespace}
\emph{This Masters Thesis/Recital Document or Doctoral Dissertation
was produced in accordance with guidelines which permit the inclusion
as part of the Masters Thesis/Recital Document or Doctoral Dissertation
the text of an original paper, or papers, submitted for publication.
The Masters Thesis/Recital Document or Doctoral Dissertation must
still conform to all other requirements explained in the Guide for
the Preparation of a Masters Thesis/Recital Document or Doctoral Dissertation
at The University of Texas at San Antonio. It must include a comprehensive
abstract, a full introduction and literature review, and a final overall
conclusion. Additional material (procedural and design data as well
as descriptions of equipment) must be provided in sufficient detail
to allow a clear and precise judgment to be made of the importance
and originality of the research reported. }

\emph{It is acceptable for this Masters Thesis/Recital Document or
Doctoral Dissertation to include as chapters authentic copies of papers
already published, provided these meet type size, margin, and legibility
requirements. In such cases, connecting texts, which provide logical
bridges between different manuscripts, are mandatory. Where the student
is not the sole author of a manuscript, the student is required to
make an explicit statement in the introductory material to that manuscript
describing the students contribution to the work and acknowledging
the contribution of the other author(s). The signatures of the Supervising
Committee which precede all other material in the Masters Thesis/Recital
Document or Doctoral Dissertation attest to the accuracy of this statement.}\end{singlespace}
\end{acknowledgements}
\begin{abstract}
The upcoming research in the Gravitational Wave domain has introduced new challenges to Astronomy and has opened a new window to the universe.

\textcolor{red}{Write abstract}

In the first chapter, I introduce the concepts and frame on which my thesis developed.

In the second chapter, I discuss the two main elements of a modern transient search. That is, Image Difference and Machine Learning classification.

\end{abstract}

\pageone{}

\chapter{Introduction}

In February 2016, celebrating the centenary anniversary of Albert Einstein's first paper on gravitational 
waves (\citet{1916SPAW.......688E})\footnote{``Approximate integration of the field equations of gravitation'' - A. Einstein. (1916)}, 
the LVC collaboration announced the first ever direct detection of a gravitational wave, coded GW150914.
With this, a new window of the universe for the purely relativistic astronomical phenomena was opened. 

The history of GW was not without controversies. 
From the discussion of whether GW would carry energy to the experiments of Joseph Weber, 
Gravitational Waves made its way from the theoretical realm into a stronghold position in Astrophysics. \textcolor{red}{Either expand or remove}

The detection of GW150914 firmly established the base for a new kind of Astronomy.
Years to come will turn GW detection, into a full field GW Astronomy.

The graviton and its wave counterpart will from now on be a new --purely relativistic in nature-- messenger of the universe.
It will bring us information about high gravitational fields, compact massive objects, relativistic speed phenomena and more.
It will let us probe into the physics of the extreme gravitational field celestial bodies.

The GW information will complete, refine and expand the understanding of our universe.
It will complement our telescopes in every light frequency band. 
For this reason, Optical Astronomy has become an even more important partner in this search.
Together they will uncover even more details of the inner mechanisms of the celestial bodies and their interactions.

In the following sections, I offer a brief introduction of GWs and their relation to Optical Astronomy.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			Gravitational Waves
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gravitational Waves}

\begin{comment}
%Quadrupole radiation is the lowest allowed form and is thus usually the dominant form. In this case, the GW field strength is proportional to the second time derivative of the quadrupole moment of the source, and it falls off in amplitude inversely with distance from the source.

%As with electromagnetic waves, GWs travel at the speed of light and are transverse in character, i.e. the strain oscillations occur in directions orthogonal to the direction in which the wave is propagating.
\end{comment}

General Relativity predicts that very massive or energetic events will create traveling perturbations of the underlying spacetime metric in the form of gravitational waves.
These are linear disturbances on a flat background metric, that are propagated outwards with the speed of light fading with the inverse of the distance.
These tensorial transversal waves will modify the local metric as it travels through space.

%Since GWs are weakly interacting, any waves produced will traverse the universe without being scattered or absorbed
Putting it in more technical terms, in an asymptotically flat spacetime, removed from any strong source so that one can assume an almost flat local solution, one can study weak perturbations to the flat Minkowski metric.
In this regime and choosing appropriate gauges, the linearized Einstein field equations present themselves in the form of a wave equation.
Solutions to this wave equations are what people refer to as Gravitational Waves.

The GW tensor metric in the TT gauge coordinate frame, has the form\footnote{We refer the reader to Appendix \ref{gwderivation} for a more complete derivation of the metric.}:

\begin{equation}
h_{\mu \nu} = 
\begin{bmatrix}
0 & 0 & 0 & 0 \\
0 & h_{+}e^{\pm i k_{\mu}x^{\mu}} & h_{\times} e^{\pm i k_{\mu}x^{\mu}} & 0 \\
0 & h_{\times} e^{\pm i k_{\mu}x^{\mu}} & -h_{+}e^{\pm i k_{\mu}x^{\mu}} & 0 \\
0 & 0 & 0 & 0 \\
\end{bmatrix}
\end{equation}

Aside from the usual sinusoidal factors for the wave propagation, we note that the GW tensor has two independent modes, or `polarizations' $h_{+}$ and $h_{\times}$. 
These polarizations are just like light polarization, except that these are at 45 degrees of each other, unlike the 90 degrees symmetry of light polarization.
To be more clear, the effect on test particles of a purely $h_{\times}$ polarization would be the same as the $h_{+}$ polarization rotated 45 degrees.

Since a spacetime metric is a measure of distance between pair of events, the metric perturbation wave will modify the relative distance between points in space as it passes by. 
It is in fact an effective oscillating strain or tidal force between free test masses.
It is in principle possible then, to devise an instrument to detect these relative differences in distance for such test masses.

But because of the very `perturbative' nature of GW, these differences are very small. 
In fact, it was Einstein himself who said in his 1916 paper ``it is obvious that $A$ [the radiation formula] has, in all imaginable cases, a practically vanishing value.''
To have any chance of detection, one must look into the extreme side of gravity: very massive compact astrophysical objects with big gravitational fields, moving at relativistic velocities.
Even the most powerful astronomical events, like a black hole merger will produce disturbances the order of $10^{-23}$m at a few hundreds Mpc of distance.

Perhaps the first experimental evidence for the existence of GWs came 50 years after their prediction with the work of Hulse and Taylor. 
For decades, they studied the pulses we receive from 
PSR B1913+16\footnote{It is also known as PSR J1915+1606, PSR 1913+16, and the Hulse--Taylor binary}, 
a Neutron Star (NS) in a Neutron Star Binary system.
The slow rate of period decrease of the pulses for this pulsar matched precisely the rate 
at which they were losing energy in Gravitational Waves, as predicted by General Relativity.
The discovery and analysis awarded them the 1993 Nobel Prize in Physics 
``for the discovery of a new type of pulsar, a discovery that has opened up new possibilities for the study of gravitation.''
This important work also settled the debate on wether GW could carry energy with them.
The decrease in period rate was proof that the energy was being radiated away into GW.

Nonetheless, a direct detection of GW wouldn't come for yet another 50 years.
In September 14, 2015, a GW detection labeled GW150914 was finally detected by the LIGO Collaboration (\cite{2016PhRvL.116f1102A}).

Direct detection {\em in situ} of GW requires a transducer of GW in some other form measurable by common instruments.

One pioneer work along this line was the work done by Joseph Weber in the late 1960s and early 70s. 
He proposed using a 2 meters in length and 1 meter in diameter aluminium cylinder, that would resonate with passing GW at 1660 Hz.
In his paper, he states that the strain oscillations on the cylinder would be of about one part in $10^{16}$.
Although very small, these tiny resonant oscillations could in principle be measured.
But even though ingenious, the carefully devised experiment could not yield positive reproducible results 
that convinced the scientific community.
It was nonetheless a very important milestone in the development of `in-situ' GW detection.
The experimental sensitivity that this experiment achieved brought us orders of magnitude closer to the required LIGO strain sensitivity.
Bar detectors like Weber's were subsequently improved. 
The latest iteration, the Nautilus GW detector ran continuously from December 1995 to December 1996.
Nautilus is a cryogenic, high Q-factor bar at a temperature of 0.1 K.
This bar has already reached a strain sensitivity of $10^{-21}$ Hz${}^{-1/2}$ in the kHz region. (\citet{1997APh.....7..231A})

A whole other category of GW detectors are those based on Michelson interferometry of lasers running on two or more kilometric long arms.
Interferometer GW detectors transduce a GW warp in space to the shrinking and stretching of relative distances of masses put far apart in two or more --mostly perpendicular-- long interferometers. 
In the case of the Earth based observatories, each interferometer is one arm several kilometers long, of an L shape facility.
The test masses are the end mirrors on each arm that reflect a laser beam pointed in each arm direction. 
On normal circumstances, the beams from two different arms can be set to be (`locked') on a dark or bright fringe of the interferometer diffraction pattern.
When a GW passes by, it will alter the relative distances of the mirror masses, thus changing the optical path of the laser beams. 
This in turn, will translate into a shift in the diffraction pattern consistent with the deformation of space.

Several of this kind are built on different parts of the planet. 
Most notably among them are the LIGO observatory (see section \ref{ligosection}) and Virgo in Europe.
GEO600 and TAMA are also detectors of this kind in Germany and Japan respectively.
Indigo is a planned observatory that will be in India.

The frequency range in which these Earth-based interferometers are sensitive depends mainly on the length of the arms.
As a rule of thumb, the length of one arm is about half the shortest wavelength it can detect.
A few kilometers long arms make them sensitive up to the kHz.
As an example, aLIGO is now sensitive in the 10 Hz --7 kHz range.

Besides the Earth-based GW interferometers, there are also advanced plans to build space based detectors.
eLISA (the Evolved Laser Interferometer Space Antenna) is a proposed GW interferometer to be set in space trailing the Earth's orbit.
Initially a NASA project, it is now an ESA mission.
eLISA will consist of three spacecrafts in an equilateral triangle configuration separated 2.5 million kilometers from each other.
The project successfully launched so far the ``LISA pathfinder'' spacecraft, whose mission is to test technologies needed for the final mission.
The final launch of eLISA is planned for 2034.
LISA will detect GW in the low-frequency band of the spectrum, roughly from 1Hz to the mHz range.

Other indirect methods of GW detection include the Pulsar Timing Array (PTA) effort.
PTA searches for correlated delays in the pulses arrival times for an array of preselected millisecond pulsars.
These delays can then be analyzed in search for signatures of passing GW.
This type of projects aim to detect very low frequency GW, from $\mu$Hz to pHz. 
Potential sources for this very low frequency signals are mergers of massive black hole binaries at the center of galaxies.

%In the following section I offer a more detailed account on the the operation of the first of these Earth based interferometers, the LIGO observatory.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			LIGO Virgo
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The LIGO-Virgo Collaboration} \label{ligosection}

\begin{comment}
The following text is mine, but too convoluted

The test masses for LIGO are two massive mirrors at the end of two perpendicular long arms (4 km long.) 
Each mirror weighs about 40 kg and each one of the arms can be thought, for simplicity, as an independent laser interferometer.

When a GW passes at an angle to this set-up, the arms will stretch and shorten in opposite directions (one arm will stretch as the other shrinks), 
while the laser keeps traveling the arms unaffected. 
This causes minuscule differences in optical paths for the light and this in turn will result in the lasers being out of phase from each other. 
This difference in phase from the `lock' position indicates a change in the relative positions of the mirrors.

Many other mundane situations can also produce this same effect, the most simple one being seismic activity of almost any strength. 
Additionally, noise from the instrument itself, from the laser beam and electronics, as well as many intrinsic vibration modes of the system complicates the output signal that will be analyzed.
\end{comment}

LIGO --the Laser Interferometer Gravitational-Wave Observatory-- (\citet{1992Sci...256..325A}) is an American observatory set to detect the GW predicted by General Relativity.

It actually consists of two separate observatories, one in the state of Washington and another one in Louisiana.

Co-founded in 1992 by Kip Thorne and Ronald Drever of Caltech and Rainer Weiss of MIT, LIGO is a joint project between scientists at MIT, Caltech, and many other colleges and universities.

Virgo is a similar observatory in Europe. 
Originally a project from France and Italy, it soon became a collaboration from five different countries: France, Italy, the Netherlands, Poland, and Hungary. 
The Virgo observatory is located in the countryside near Pisa, Italy.

Since 2007, LIGO and Virgo share their data in an umbrella collaboration named LVC, the LIGO-Virgo Collaboration.

Even though, LIGO and Virgo have comparable noise levels and detection rates, only the two interferometers in LIGO were operational at the time of the GW150914 event. 
In fact, Virgo was being upgraded to Advanced Virgo, which will have a sensitivity 10 times greater than Initial Virgo. 
When the upgrade is finished, it will join LIGO in the joint collection of GW data. This will improve errors in the parameter estimation, especially localization errors will greatly improve.

LIGO went through similar upgrades along the years.

Each LIGO observatory consists of two long arms, 4 km long of an isolated, vacuum tube where the lasers run and hit the mirror test masses.
The initial LIGO detectors were designed to be sensitive to GWs in the frequency band 40-7000 Hz, and capable of detecting a GW strain amplitude as small as one part in $10^{21}$.

To picture the order of magnitude of these displacements, consider that the change in length of one arm of the interferometer 
is only about $10^{-18}$ m, a thousand times smaller than the diameter of a proton.

To reach this sensitivity, the detectors need highly stable lasers, multiple layers of vibration isolation and advanced optic techniques.

From the initial period, LIGO had five short science runs (each labelled S1 to S5), each one improving over the previous one, 
culminating with S5 at design sensitivity. 
The S5 run collected a full year of triple-detector coincident data from November 2005 to September 
2007.\footnote{At the time of Initial LIGO there were 3 detectors operating, 2 in Louisiana y and 1 in Washington.}

Between Initial LIGO and Advanced LIGO (aLIGO) more science were made under Enhanced LIGO, 
which provided enhancements that improved sensitivity by a factor of 2. 

But the real revolution came with Advanced LIGO, a set of additions that improved LIGO sensitivity by a factor of 10 over Initial LIGO 
and widened the frequency range all the way down to 10 Hz (known as the {\em seismic wall}).

Among the improvements is the upgrading of the laser power to 200 W. 
An increase in the test masses to 40 kg in order to reduce radiation pressure noise and to allow larger beam sizes. 
Larger beams and better dielectric mirror coatings combine to reduce the test mass thermal noise by a factor of 5 compared with initial LIGO.
An improvement in vibration isolation, including vertical isolation comparable to the horizontal isolation all almost all stages.
New suspension system based on fused silica rather than steel wires to reduce suspension thermal noise by almost a hundred.
New two-stage active seismic isolation instead of the passive one-stage isolation brought the seismic noise to negligible levels above approximately 10 Hz.
(\citet{2009RPPh...72g6901A})

All these improvements combined gave Advanced LIGO a 10-fold increase in sensitivity. 
This increase also means that fainter sources can now be detected, increasing the exploration volume for GW by a factor of a thousand.

Advanced LIGO will have several observations runs, labelled O1, O2, etc. (similar to the scientific runs S1-S5) 
with gaps between them on which more improvements will be implemented until it reaches design sensitivity.

The projected sensitivity for each of the runs is presented in table \ref{ligoruns} (\citet{2016LRR....19....1A, 2014ApJ...795..105S})


\begin{table}
\centering
\begin{tabular}{*{9}{|c}|}
  \hline
   & Estimated & 
  \multicolumn{2}{c|}{$E_{GW} = 10^{-2}M_{\odot}c^2$} &
  \multicolumn{2}{c|}{}
  & Number &
  \multicolumn{2}{c|}{\% BNS Localized} \\
   & Run & 
  \multicolumn{2}{c|}{Burst Range (Mpc)}&
  \multicolumn{2}{c|}{BNS Range (Mpc)} &
  of BNS &
  \multicolumn{2}{c|}{within} \\
  Epoch & Duration & 
  LIGO & Virgo &
  LIGO & Virgo &
  Detections &
  5 deg${}^2$ & 20 deg${}^2$ \\ \hline
2015 & 3 months & 40 -- 60 & --- & 40 -- 80 & --- & 0.0004 -- 3 & --- & --- \\ 
2016-17 & 6 months & 60 -- 75 & 20 -- 40 & 80 -- 120 & 20 -- 60 & 0.006 -- 20 & 2 & 5 -- 12 \\
2017-18 & 9 months & 75 -- 90 & 40 -- 50 & 120 -- 170 & 60 -- 85 & 0.04 -- 100 & 1 -- 2 & 10 -- 12 \\
2019$+$ & (per year) & 105 & 40 -- 70 & 200 & 65 -- 130 & 0.2 -- 200 & 3 -- 8 & 8 -- 28 \\
2022$+$ (India) & (per year) & 105 & 80 & 200 & 130 & 0.4 - 400 & 17 & 48 \\ \hline
\end{tabular}
\caption{LVC Observation Runs Projection}
\label{ligoruns}
\end{table}

\textcolor{red}{Needs to add: Observables of LIGO, especially Compact Binary Mergers. Rates, etc.}


%The detectors provided unprecedented sensitivity to gravitational waves over a range of frequencies from 30 Hz to several kHz [1], 
%which covers the frequencies of gravitational waves emitted during the late inspiral, merger, and ringdown of stellar-mass binary black holes (BBHs).


\begin{comment}
%The successful operation of Advanced LIGO is expected to transform the field from GW detection to GW astrophysics. We illustrate the potential using compact binary coalescences. Detection rate estimates for CBCs can be made using a combination of extrapolations from observed binary pulsars, stellar birth rate estimates and population synthesis models. There are large uncertainties inherent in all of these methods, however, leading to rate estimates that are uncertain by several orders of magnitude. We therefore quote a range of rates, spanning plausible pessimistic and optimistic estimates, as well as a likely rate. For a NS mass of 1.4 sm and a BH mass of 10 sm, these rate estimates for Advanced LIGO are: 0.4 400 yr, with a likely rate of 40 yr for NS–NS binaries; 0.2 300 yr , with a likely rate of 10 yr for NS–BH binaries; 2 4000 yr, with a likely rate of 30 yr for BH-BH binaries.

LIGO was designed so that its data could be searched for GWs from many different sources. The sources can be broadly characterized as either transient or continuous in nature, and for each type, the analysis techniques depend on whether the gravitational waveforms can be accurately modeled or whether only less specific spectral characterizations are possible. We therefore organize the searches into four categories according to source type and analysis technique.
%(i) Transient, modeled waveforms: the compact binary coalescence search. The name follows from the fact that the best understood transient sources are the final stages of binary inspirals [52], where each component of the binary may be a NS or a BH. For these sources the waveform can be calculated with good precision, and matched-filter analysis can be used.
(ii) Transient, unmodeled waveforms: the gravitational-wave bursts search. Transient systems, such as core-collapse supernovae [53], BH mergers and NS quakes, may produce GW bursts that can only be modeled imperfectly, if at all, and more general analysis techniques are needed.
(iii) Continuous, narrow-band waveforms: the continuous wave sources search. An example of a continuous source of GWs with a well-modeled waveform is a spinning NS (e.g. a pulsar) that is not perfectly symmetric about its rotation axis [54].
(iv) Continuous, broadband waveforms: the gravitational-wave background search. Processes operating in the early universe, for example, could have produced a background of GWs that is continuous but stochastic in character [55].
\end{comment}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			The Transient Universe
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Transient Universe}

In this so-called ``Information Age'', data is king.
As we move away from the traditional one person project and manual way to deal with information, 
the amount of data that needs processing becomes unmanageable by humans. 
This is not to say that individual work has no place in science, but that the collective gathering of information have become ubiquitous.

For Astronomy, the sizes of sky surveys have been increasing steadily and dramatically over the years.
From a situation where data lies in the hundreds of MB and about a hundred events per night now, 
we are heading to a regime of several tens of TB and the order of million events per night in the 
LSST\footnote{http://www.lsst.org, http://www.lsst.org/files/docs/sciencebook/SB\_8.pdf} era 
(\citet{2008arXiv0805.2366I, 2009arXiv0912.0201L}).
The data load makes it unmanageable if not done by automated agents.

Buried in this huge amount of data, lie many short-lived events, or {\em transients}, that will only be registered for a short period of time.
Although ephemeral, these transient events can uncover important information on the nature and evolution of the universe.
The most striking example is the discovery of Super Novae events that brought invaluable information on the final stage of stars.

The time scales of transient events cover over several orders of magnitudes.
They can last from milliseconds, like Fast Radio Bursts, to a span of tens of days like Super Nova (SN) explosions, and these can fade away in as much as hundreds of days.
Some of these events are recurring, with or without predictability of the next event, and some of them are only a one-time occurrence.

\begin{comment}
List of transients:
- soft gamma repeater (SGR) flares; these are highly magnetized (1015G) neutron stars that emit gamma-ray flares sporadically
- M-dwarf flares occur and disappear within minutes but recur often although unpredictably
\end{comment}

Transient events are present in --and enhanced knowledge of-- almost every field of Astronomy.
They are most often unpredictable, they do not have periodic variability, and will only last for a relatively short period of time, 
this make it necessary to study them in the field of time domain.

Nonetheless, time domain astronomy poses at least two big main challenges.
The first one deals with the huge amount of data and the process of recovering interesting transients from it. 
This is a {\em Data Mining} problem.

The second challenge has to do with the prompt dissemination of a transient discovery
to the scientific community to do follow-up observations in different bands of the spectrum.
The huge interest in Gamma Ray Bursts propelled most of the infrastructure that we have now to deal with this issue.
We cover {\em multi-messenger Astronomy} (MMA) and some examples of it in the following sections.

\subsection{Mining Transients}

The identification of transients in data sets hast to be done against the static or slowly varying background sky.
Fortunately for us, a huge portion of transients, even though they may be fundamentally different phenomena, look about the same at the instance of discovery.
That is, new transient phenomena presents itself on an image, as a new or much brighter spot, relative to previous epochs.

There are basically two main methods to unbury transients from images.
Both of the transient retrieval methods require a comparison with a reference and a search that tries to find unexpected objects for that region of the sky.

The first kind is based on catalogs. 
In this method, a calibrated catalog of sources is done on a new image and compared against a reference catalog.
Then we search for correlation in both sets of catalogued objects, looking for either spatial position matches or intensity matches.
The unmatched sources --by position or intensity-- are potential candidates to transients.

The second method uses a reference image, but relies on a carefully done subtraction against the new image.
This subtraction tries to compensate for different point-spread functions (PSF), different background levels or different gains between the two epochs.
After the subtraction is done, a source-detection algorithm is run over the subtraction image searching for any residual sources.
These residual sources are the candidates for transients.

Each method has its advantages and disadvantages, difference image is typically more computationally expensive but 
performs well around extended objects such as galaxies, it can detect variability in non-stellar profiles, and can perform better in crowded fields.
It also has the biggest disadvantage of leaving many spurious residual objects from poorly subtracted star profiles. 
This can be compensated by Machine Learning methods, as we shall see later.

The best advantage of catalog-based methods is that they don't require reference images and are typically computationally less intensive.
It has also the advantage that can handle better catalogs from different telescopes.
The disadvantage is that it requires more careful photometric and astrometric calibration and does not perform as well near extended objects.

In either case, the task remain to identify interesting transients after we `mined' our images looking for potential candidates.
Such classification of transient events is nowadays done with the aid of classification agents trained with Machine Learning techniques.
Machine Learning classifiers can sort out the relevant transients from a pile of thousands in an effective and fast way, 
enabling rapid follow-ups that would be impossible with a manual approach. 
Especially so if the transients of interest are rare and data is highly contaminated.

We will cover Machine Learning classifiers in future chapters.

\begin{comment}

Variability of the sky usually refers to changes in brightness, \textcolor{blue}{but the position or color of the object could vary instead or as well.}

\textcolor{blue}{copy-paste}However, there is yet another twist - how to identify the target objects of interest among the background of millions of other potential variable or transient objects? ... this results in a pool of candidates contaminated with other variables or transients. Reducing that contamination requires additional observational data either to determine the full shape of the transient or variable lightcurve, or to determine the velocity and acceleration vectors of a solar system object, or to determine the spectral energy distribution of the object through observations at multiple wavelengths or in multiple filters.
The process of winnowing out the contaminants and identifying the true members of the target sample is the heart of ``classification''.

This advantage can be also a curse when we want to isolate a particular kind of transient interesting to our project.
As we said before, transients of many kinds look about the same on an image.
This means that capturing transient events on an image is not enough.
For example, moving objects and objects in our solar system have to be regarded as contamination if we are interested in extragalactic phenomena.

\end{comment}

\subsection{Multi-Messenger Astronomy}

The second challenge relates to the issue of multi-messenger Astronomy.
One event discovered with a certain messenger, could be studied in all the other frequencies.
For this the transmission of the information on localization has to be sent faster than the typical duration of the event.
This is especially true with afterglows of very energetic events.

An event like a SN explosion may be first detected as a long GRB event in one of the space based Gamma Ray Telescopes orbiting Earth.
This information needs to be quickly sent to the Astronomy community to study emission it in the optical, infrared, radio as well as the spectroscopy.

It was actually GRBs what ignited excitement in the astronomy community about transient astronomical events, 
it was one of the first objects to be studied in a multi-band fashion, 
and it triggered most of the infrastructure we see today to deal effectively with multi-messenger astronomy.

Gamma Ray Busts were first discovered by the Vela satellites, a set of 6 pair of satellites (Vela 1a,b through Vela 6a,b) 
launched by the United States to orbit the Earth. 
The original purpose of the array of satellites was to monitor the nuclear activities of other countries during the Cuba Missile Crisis in the 60's.
The satellites were designed to detect the hard-to-shield high energy signature emissions ($\gamma$ and X rays) of nuclear detonations.
Instead of this, they found strange very energetic bursts of gamma rays coming from outer space (\citet{1973ApJ...182L..85K}).

The many GRBs detected in the first few decades rapidly show that the direction they were coming were isotropically distributed in the sky.
Although suggestive, this alone was not enough to conclude the extragalactic origin of GRBs. 
Given the huge scale of energies involved, many people favored the idea that GRBs \textcolor{red}{were being produced in the halo of our Milky Way. (re check)}
More data was needed to resolve this issue.

In the late 1970s, NASA approved the construction of a new telescope that would be ten times more sensitive than previous GRB detectors in space 
and that would detect about 1 GRB a day with a 10 degree precision in localization. 
It was finally launched on April 5, 1991.
Unfortunately, BATSE could not help in the optical afterglow localization of GRBs.

But it was BeppoSAX (formally, the ``Satellite per Astronomia a Raggi X''), 
an Italian satellite equipped with a GRB monitor and an X-ray coded mask imager, 
the one that would bring us closer to scan the multiband afterglow.

BeppoSAX X-ray imager could find X-ray counterparts for GRBs, and narrow the localization uncertainty to 5 to 10 arcminute radius.
This was already possible with the network of GRB detectors in space at the time, 
but it involved cross-analyzing data from diverse sensors and the process took several days to finish.
It was known at the time that there were no optical counterparts after a week of the event.
If we wanted to find optical afterglows, we would need to find more accurate localization much faster.
BeppoSAX did precisely that, it reduced the time of localization to only a few hours.

This reduction in the time of localization opened the game for telescopes around the globe to try to find optical and radio afterglows.
On February 28, 1997 BeppoSAX localized a GRB with an X-ray counterpart that vanished after 3 days.
Twenty hours after the GRB event, a group from the Netherlands lead by Jan van Paradijs, 
used La Palma telescope in Canary Islands, Spain to image the region.
This was the first time an optical afterglow could pinpoint the sky position down to the unprecedented precision of 1 arcsecond.
Hubble Space Telescope (HST) imaged the region and a blue blob appeared. 
Unfortunately this was not enough to confirm or deny an extragalactic origin.

About two months later, on May 8, 1997, BeppoSAX detected another GRB and a compatible X-ray counterpart.
Caltech imaged the uncertainty region using Keck II telecsope in Hawaii and found a clear optical afterglow.
This afterglow and its spectrogram confirmed that GRB970508 was 5 Gpc away.

This discovery and the subsequent follow-up observations finally settled the debate on the origins of GRBs.
GRBs were clearly of extragalactic origin.
Furthermore, radio follow-up observations, along with the estimated distance from optical, 
strongly suggested that the emitting surface was expanding at close the speed of light.
The distance estimation greatly helped understanding the intrinsic luminosity and possible mechanisms for it.

\textcolor{red}{Find if MMA also made the link between long GRBs and stellar core collapse}

So much more was there to find about GRB970508 and GRBs in general, 
but the foundations of MMA were laid for the future.
GRBs were a complete enigma until fast event dissemination enabled for multi-band identification of afterglows.


\begin{comment}

From Bloom's book:  Joshua S. Bloom. What Are Gamma-Ray Bursts?.
To settle the questions about the peculiarities of the data collected over multiple telescopes, a single experiment was required, whose sky coverage and trigger efficiencies were well modeled, capable of detecting GRBs to significantly fainter levels than before. Such an experiment had been in construction at Marshall Space Flight Center (in Huntsville, Alabama) throughout most of the 1980s, having been accepted for funding by NASA in the late 1970s. The Burst and Transient Source Experiment (BATSE) was launched by space shuttle Atlantis on April 5, 1991, on board the Compton Gamma-ray Observatory (CGRO; along with three other high-energy experiments). BATSE was about ten times more sensitive than previous GRB missions, allowing it to find roughly one burst a day for what would be its nine-year mission.
For the first time, a single satellite would be capable of positioning a GRB to ~10 degrees on the sky.

It was abundantly clear in 1995 that new observations would be needed to settle the distance scale debate once and for all. Just as always, the main hope remained to find a precise location of classical GRBs and associate those positions with known objects. Since the single-satellite precision of BATSE was about as good as that detector configuration could provide, the key was to find counterpart events at other wavebands. It was known from precise IPN locations that no long-lived (weeks to months) optical transient accompanied the events. But thanks to the nearly instantaneous relay of new GRB positions from BATSE, several groups began construction of optical telescopes awaiting email alerts from GRB satellites; this new generation of telescopes was capable of rapidly observing new GRB positions. If GRBs were accompanied by optical flashes lasting just a few minutes, the robotic on-call telescopes would have a chance of catching the fleeting light. Theory of GRB emission mechanisms, developed in the early 1990s, also predicted radio transients from GRBs (chapter 3); as such, some groups began a search at radio wavebands with premier facilities like the Very Large Array (VLA) in New Mexico. None of the early searches of BATSE positions proved fruitful.

While GRBs were not the main scientific priority of a new Italian-Dutch experiment, the ``Satellite per Astronomia a Raggi X'' (commonly known as BeppoSAX), it did carry a Gamma-Ray Burst Monitor (GRBM) that stared at the same place on the sky as the X-ray-coded mask imagers (collectively called the Wide-Field X-ray Camera [WFC]); those instruments were capable of seeing roughly 1/15th of the sky at any time. 
Launched in April 1996, BeppoSAX demonstrated that summer that a burst triggered in the GRBM and seen in the WFC field of view could be localized to about 5-10 arcminute radius. 
Such localization accuracy was often obtained with the IPN, but BeppoSAX had the ability to determine such positions in a matter of a few hours, whereas IPN localizations typically took days to determine. 
The speed of finding a precise GRB position would prove to be a crucial capability.

On February 28, 1997, BeppoSAX localized a GRB using the WFC and the GRBM and found a good-enough position to command the satellite to repoint to allow its Narrow-field X-ray Instruments (NFI) to image the GRB region. Just eight hours after the GRB, two of the NFI cameras detected a bright, new X-ray source consistent with the WFC position. Three days later, that source had vanished.

Not only had the BeppoSAX team found the first afterglow of a GRB, the X-ray afterglow was positioned well enough (to 50 arcseconds in radius) to allow for sensitive searches of counterparts at other wavelengths. Just twenty hours after the GRB, a group led by Jan van Paradijs at Amsterdam University, the Netherlands, obtained a set of deep optical images of the WFC error location from La Palma Observatory on the Canary Islands (Spain). One week later, my collaborator (Nial Tanvir) obtained the next set of images of that field from the same observatory. A faint source in the NFI error box had vanished between those two epochs: it was the discovery of the first fading optical (i.e., visible-light) afterglow of a GRB. The optical position, determined to better than 1 arcsecond, was by far the best localization of any GRB, including the March 5th (SGR) event.

As the optical afterglow faded, the Hubble Space Telescope (HST) was trained on the position and found a blue blob around the fading afterglow. To most, this ``nebulosity'' looked a lot like a faint low-surface brightness galaxy, thus confirming the extragalactic hypothesis; but to the stalwarts of the Galactic model, it looked like an NS-blown bubble (confirming the opposite). Despite some claims from a few that the afterglow appeared to be moving on the sky (a nominal expectation of the Galactic model) and that the nebulosity changed color and shape (only possible in the Galactic model), all doubts about the distance scale of classical GRBs would be soon laid to rest.

On May 8, 1997, BeppoSAX spotted another GRB, and an optical afterglow was promptly discovered consistent in location and time with another fading X-ray afterglow. Astronomers at the California Institute of Technology (Caltech) obtained a spectrum of the optical afterglow using the Keck II 10-meter telescope in Hawaii; this telescope (and its twin Keck I) was the largest optical telescope in the world at the time. A quick inspection of that data led to one of the biggest discoveries in modern astrophysics: notched out of an otherwise smooth spectrum were a series of absorption lines, characteristic of iron and magnesium in gaseous form. But instead of seeing lines at the specific wavelengths as they would appear in a laboratory, they all appeared shifted to significantly redder wavelengths.* This redshift effect was immediately recognized as an effect due to the expansion of the Universe, and, given a reasonably well-prescribed mapping between the redshift measurement and distance, this observation established that GRB 970508 must have occurred from a distance of more than about 5 billion parsec (i.e., 5 Gpc) away. Some gas cloud in a distant galaxy lay between us and the GRB,26 and its absorbing metals provided enough of a unique fingerprint to measure an unambiguous redshift.

In one fell swoop of the telescope, the thirty-year marathon to measure the distance scale of classical GRBs was won. The cosmological distance scale, the disfavored choice of so many for so long, had triumphed. To top it off, the first radio afterglow of a GRB was found following GRB 970508. A detailed inspection of the way in which the radio afterglow behaved, coupled with the then-known distance, strongly suggested that the afterglow-emitting surface was expanding at a rate close to the speed of light. This relativistic expansion, which we will explore in 2.2.1, was a basic prediction of most cosmological theories of GRBs?another triumph for observers and theorists alike.

------------------------------------------------------------

GRBs are explosions as energetic as $10^{51}$-$10^{52}$ ergs, liberated Gamma Rays and subsequent afterglows across the whole spectrum up to radio frequencies.
The afterglows for GRBs can be seen in the optical as a transient brightness excess, usually located near the galaxies that host them. 
GRBs can be at extremely distant galaxies, and therefore optical glows can sometimes be too faint to observe.

According to \textcolor{red}{Batse} data, GRBs seem to come from two distinct population.
Histograms done on the time time to receive 90\% of the radiation, or $T_{90}$ seem to indicate the populations are
divided into `long' and `short types'. Long GRBs last for longer than 2s, while short duration GRBs have $T_{90}$ values under 2s.

Long GRBs are associated with massive star collapse (E. Waxman and J.N. Bahcall, ApJ 541, 707 (2000).) 
producing $\gamma$-rays then subsequent X-rays and optical afterglows


%Long GRB events are assumed to be produced by massive star collapse, and GW searches by LIGO and Virgo use their unmodeled burst search pipelines
%F. Acernese et al (Virgo Collaboration), Class. Quantum Grav. 25, 225001 (2008).
%B. Abbott et al (LIGO Scientific Collaboration), Phys. Rev. D 72, 042002 (2005).
%B. Abbott et al (LIGO Scientific Collaboration), Phys. Rev. D 77, 062004 (2008).
%B. Abbott et al (LIGO Scientific Collaboration and the Virgo Collaboration), ApJ 715,

%The coalescence of a neutron star - neutron star, or neutron star - black hole binary system is suspected to be the source of the short GRBs; the LIGO-Virgo compact binary coalescence and burst pipelines are both used to search for GWs from short GRBs
%J. Abadie et al (LIGO Scientific Collaboration and the Virgo Collaboration), ApJ 715, 1453 (2010).

%Since the detection of the first few of these, now we have two space telescopes dedicated to find them.
%Swift reference http://swift.gsfc.nasa.gov/docs/swift/swiftsc.html
%Fermi reference http://fermi.gsfc.nasa.gov/

A double neutron star (NS) or NS/blackhole merger could be the source of short GRBs (E. Nakar, Phys. Rep. 442, 166 (2007).)

To detect the optical afterglow, GRB locations were communicated to other observatories that would promptly point their telescopes in that direction.
A multi-band observation and spectrography is very valuable for the understanding and classification of these events.

\end{comment}

The prompt dissemination of GRB discoveries became so important that sparked the creation of a collective centre for transient discovery notification.
The Gamma-Ray burst Coordinates Network (GCN) and the Transient Astronomy Network (TAN), 
collectively called the GCN/TAN network\footnote{https://gcn.gsfc.nasa.gov},
is a distribution network of transient events notices dependent on Goddard NASA.

The GCN/TAN disseminates transient event information mostly in real time, while the event is still ongoing, or with short delay depending on the instrument,  
detected by various spacecrafts (Swift, Fermi, MAXI, INTEGRAL, IPN, and others).
It also serves as a repository for the follow-up observation reports submitted by the GRB/transient community through the use of GCN Circulars.

Although the creation of GCN/TAN was propelled by the interest in GRBs, now it serves as a point of communication for all sort of transient events.
In the LIGO-Virgo era, GCN/TAN now also serves GW detection notices to some selected observatory partners (of which TOROS is one).

With the new GW detections of LIGO, a new kind of multi-messenger Astronomy is at hand.
LIGO will bring information of a completely new information carrier: the {\em graviton}.

In the same way that long GRBs sparked the multi-band follow-up observations across the spectrum,
a new type of event associated with short GRBs can also prompt a new kind of MMA.
Short GRBs are believed to have originators in the merger of compact objects (degenerate stars).
Compact object mergers are also the originators of the expected GW signals that LIGO will detect.
Along with the GW produced in these mergers, a companion EM thermal radiation will radiate isotropically from the merger.
This EM counterpart, is believed to shine about a thousand times brighter than a Nova, and it was named accordingly 
`Kilonova'\footnote{It is also reference in the literature under the name {\em macronova}}.
Just as in the case for GRBs, Kilonovas can narrow the localization of GW to a few arcseconds.

Conversely, if there is a chance to detect the relatively faint Kilonova, it will be greatly helped if we have prompt information of its GW counterpart, or its associated GRB.

It is then very important to complement such information with the EM counterpart.
Both, the GW and the EM information can bring up a more complete picture of the phenomena at hand.
Together they can give us an understanding richer than the sum of their separate contributions.
Even more, EM counterparts can most notably help where GW information fails harder, in localization.
Localization by means of the EM counterpart, not only helps on this few parameters of the position in the sky, 
but will also help to separate the uncertainty correlation on the geometrical disposition of a merger, for example.
This way, improving other estimates for the parameters of the merge.


\textcolor{red}{Add: GW can trigger searches for optical counterparts, but the inverse is also true.}
% There are efforts to search for GW in ligo data triggered by optical observations.
% E. Thrane et al, Phys. Rev. D 83, 083004 (2011).

\begin{comment}

Long and short GRB afterglows peak a few minutes after the prompt EM/GW emission
(\citet{2011ApJ...734...96K, 2010ApJ...720.1513K})
and it is critical to have EM observations as soon as possible after the GW trigger validation. 
Kilo-novae model afterglows peak about a day after the GW emission (\citet{2010MNRAS.406.2650M})
so EM observations a day after the GW trigger would be an important validation for these type of events.

\textcolor{blue}{LSST will send out public VOEvents describing the millions of transient and variable detections each night. 
Huge databases (upwards of 12 PB for LSST at the end of its 10 year survey) of objects and all of their detections will be created and available for queries. 
Users will be able to use this database to identify and classify the target samples of interest to them, as well as access the VOEvent stream to get real-time updates on targets.}

\textcolor{blue}{Thus we expect the infrastructure for astronomical transients to allow end-users to select in advance what types of events they want, and we expect specialist ``event brokers'' that disseminate only certain kinds of transients to their target audiences. 
Such dissemination should happen quickly, so that the essential telescope resources can be directed for follow-up, and we expect these decisions to be taken automatically by machines.}

\textcolor{blue}{the IVOA has settled on a flavor of XML called VOEvent for the transmission of astronomical events, and processing those would need XML streaming and filtering technologies.}

\end{comment}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			Kilonova
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Kilonova, A New Case For Multi-Messenger Astronomy} \label{kilonovachapter}

It has long been suggested, both by observational and theoretical grounds, 
that Binary Compact Mergers --where at least one of the merging bodies is a NS-- are the progenitors for the short class of GRBs. 
But it was not until the late 90's that a second class of EM emission was theorized to be present during these type of merging events.

This new class of thermal emission would be powered by the radioactive heating from the decay of heavy nuclei formed in the neutron-rich merge ejecta, driven by the so-called r-process.

%\textcolor{blue}{This emission provides both a robust EM counterpart to the GW chirp, which is expected to accompany a fraction of BH-NS mergers and essentially all NS-NS mergers.}

Unlike short GRB emission, where most of the energy is collimated into a radiation beam, Kilonova emission is isotropic.
It lasts for about a week and it peaks in the NIR sector of the light spectrum. 
The intensity of such event can reach brightness of a thousand times those of a Nova, and for this reason it was termed `Kilonova' (\citet{2010MNRAS.406.2650M}).

Rapid neutron capture, or r-process for short, is the main driver of the radiation we see during a Kilonova.
In dense neutron-rich environments, if the neutron capture timescale of lighter seed atom nucleus (like Iron) 
is shorter than the neutron beta-decay timescale, nuclei can capture extra neutrons for themselves.
The newly formed nuclei will later decay emitting radiation.
\citet{1957RvMP...29..547B} and \citet{1992ApJ...395L..83N} had already proposed that approximately half of the elements heavier than iron are synthesized in this way.

This EM transient powered by the radioactive heating of the r-process, is what is called a Kilonova.
This radioactive heating occurs through a combination of $\beta$-decays, $\alpha$-decays, 
and fission of the r-process nuclei (\citet{2010MNRAS.406.2650M, 2016ApJ...829..110B, 2016MNRAS.459...35H})

During a Binary NS merger, the decompression of highly neutron-rich ejecta is a favorable environment for rapid neutron capture process.
The BNS ejecta consists mainly of matter ejected either by tidal forces or compression-induced heating at the interface between merging bodies. 
Unbound debris from the merger can also form a disk around the merge and outflows from this disk is another --albeit second in importance-- source of ejecta.

As a first approximation we can imagine the ejecta expanding radially outwards with spherical symmetry.
Ejecta right after the merger can exceed billions of degrees at the radius of the merger (100 km), but 
during its expansion, the ejecta cools down due to adiabatic expansion.

The thermal radiation cannot initially escape as radiation because of the high optical depth at early times and the correspondingly long photon diffusion timescale through the ejecta. 
Nonetheless, as the ejecta expands, the diffusion time decreases until eventually radiation can escape and the medium becomes transparent to radiation.
The condition at which ejecta first becomes transparent is crucial since it determines how much after the GW signal will the light curve peak.

Devoid of any other external source of heating, the ejecta would be so cold when it first becomes transparent, 
that the whole transient would be basically invisible.
It is the continued heating of the ejecta by external processes what can brighten the Kilonova.

%At a minimum, the ejecta receives heating from the radioactive decay of heavy nuclei synthesized in the ejecta by the r-process.
As we mentioned before, the primary heating mechanism is the radioactive heating by r-process nuclei decay.
This alone is enough to heat the environment to shine as much as 1,000 times brighter than a Nova.
Nonetheless other contributions to the main heating rate of the ejecta are important to determine 
the key observables of the Kilonova such as peak time, luminosity and effective temperature of the ejecta.

% Here other heating mechanisms

% The process just described is the current paradigm of Kilonova emission.
% Other EM components that are not derived from this mechanism are 
% about day-long optical (?blue?) emission from lanthanide-free components of the ejecta;
% an hour- long precursor UV/blue emission, powered by the decay of free neutrons in the outermost ejecta layers (macronova); 
% and enhanced emission due to energy input from a long-lived central engine, such as an accreting BH or millisecond magnetar.

In the BH-NS merger case, there is a chance of Kilonova emission if there is enough NS disruption 
to get a suitable environment with enough neutron rich ejecta to spark r-process and the subsequent radioactive heating.
This can only happen in situations where the BH mass is low enough so that it won't swallow the NS entirely during the inspiral phase and if the BH is rotating rapidly.
The condition is roughly that the tidal radius of the NS exceed the innermost stable circular orbit of the BH.
For a NS of radius 12 km and mass 1.4 solar M, the BH mass can be as high as 12 solar masses (for a spin parameter of 0.95) but not higher.
A non-spinning BH would have to be very small to allow for tidal disruption and hence will yield a non-detectable signal.
(\citet{2012PhRvD..85d4015F} and references therein).

Finally, even thought BH-BH mergers can have strong GW emission signals, they lack EM counterpart, 
except perhaps in very specific situations, mainly due to lack of baryonic matter.

The end product of a NS-NS or BH-NS merger is a central compact remnant, either a BH or a NS.
In the case of Binary NS systems, if the total mass of the original system exceeds a critical mass $M_{crit}$
the remnant NS will collapse into a BH essentially immediately, on the dynamical time of milliseconds or less
(\citet{2011PhRvD..83l4008H, 2013ApJ...773...78B}).
The actual value for $M_{crit}$ is highly dependent on the equation of state (EOS) chosen for the NS, 
but it ranges between 2.6 and 3.9$M_{\odot}$.

Below the $M_{crit}$ value, we can still have a NS remnant supported by rotation, at least temporarily.
A massive NS remnant, which is supported exclusively by its differential rotation, is known as a {\em hypermassive} NS (HMNS).
(\citet{2000ApJ...528L..29B, 2010ApJ...724L.199O, 2014ApJ...790...19K})

If the NS remnant is somewhat less massive, it can also be supported by its solid body rotation and it is known as a {\em supramassive} NS (SMNS).
HMSN will decay rapidly into a BH after a few hundreds milliseconds after the merger, while SMNS can remain stable for minutes or much longer before collapsing
(\citet{2006PhRvD..73f4027S, 2006PhRvL..96c1101D, 2013PhRvD..87l1302S}).
Finally, if the NS remnant has a total mass less than the maximum mass of a non-rotating NS, it will remain a stable NS
(\citet{2008ApJ...676.1130M, 2013ApJ...771L..26G}).

At least a moderate fraction of NS-NS mergers are likely to be supramassive (\citet{2010ApJ...724L.199O}), if not indefinitely stable.
Energy input from such long-lived remnants could substantially enhance the kilonova emission.

\begin{comment}


The variety of sources which contribute to heating the ejecta, particularly on timescales when the ejecta is first becoming transparent, 
will determine the specific characteristics of the light-curve of the Kilonova.

At a minimum, the ejecta receives heating from the radioactive decay of heavy nuclei synthesized in the ejecta by the r-process.

* Infrared Emission

In the tidal tails in the equatorial plane, or in more spherical outflows from the accretion disk in cases when BH formation is prompt or the HMNS phase is short-lived, the highly neutron-rich matter (Ye < 0.29) will form heavy r-process nuclei.
This r-process will peak in the near infra-red (NIR) at J and K bands (1.2 and 2.2 μm, respectively) on a timescale of several days to a week.

* Blue Emission

In addition to the highly neutron-rich ejecta (Ye < 0.29), growing evidence suggests that some of the matter which is unbound from a NS-NS merger is less neutron rich (Ye > 0.29; e.g. Wanajo et al. 2014a; Goriely et al. 2015) and thus will be free of Lanthanide group elements (Metzger \& Fernandez 2014). This low-opacity ejecta can reside either in the polar regions, due to dynamical ejection from the NS-NS merger interface, or in more isotropic outflows from the accretion disk in cases when BH formation is significantly delayed.
By assuming a lower opacity appropriate to Lanthanide-free ejecta, the emission now peaks at the visual bands R and I, on a timescale of about 1 day at a level 2-3 magnitudes brighter than the Lanthanide-rich case.

In general, the total kilonova emission from a NS-NS merger will be a combination of `blue' and `red' components, as both high- and low-Ye ejecta components could be visible for viewing angles close to the binary rotation axis (Fig. 4). For equatorial viewing angles, the blue emission is likely to be blocked by the higher opacity of the lanthanide-rich equatorial matter (Kasen et al. 2015). Thus, although the week-long NIR transient is fairly generic, an early blue kilonova will be observed in only a fraction of mergers.

* Magnetar remnant KN

The type of compact remnant produced by a NS-NS merger (e.g. prompt BH formation, hypermassive NS, supramassive NS, or indefinitely stable NS) depends sensitively on the total mass of the binary relative to the maximum mass of a non-rotating NS, Mmax($\Omega$ = 0). The value of Mmax($\Omega$ = 0) exceeds about 2solar masses (Demorest et al. 2010, Antoniadis et al. 2013) but is otherwise unconstrained by observations or theory up to the maximum value about 3solar masses set by the causality limit on the EOS. A `typical' merger of two about 1.3-1.4sm NS results in a remnant mass of about 2.3-2.4sm after accounting for neutrino losses and mass ejection (e.g., Belczynski et al. 2008). If the value of Mmax($\Omega$ = 0) is well below this value (e.g. 2.1-2.2sm), then most mergers will undergo prompt collapse or form hypermassive NSs with very short lifetimes. On the other hand, if the value of Mmax($\Omega$ = 0) is close to or exceeds 2.3-2.4sm, then a order unity fraction of NS-NS mergers could result in long-lived supramassive or indefinitely stable remnants.

If the rotational energy could be extracted in non-GW channels on timescales of hours to years after the merger (e.g., by magnetic dipole radiation), this could substantially enhance the EM emission from NS-NS mergers (e.g. Gao et al. 2013; Metzger \& Piro 2014; Gao et al. 2015; Siegel \& Ciolfi 2016a). However, for NSs of mass Mns   Mmax($\Omega$ = 0), only a fraction of the rotational energy is available to power EM emission, even in principle. This is because the loss of angular momentum that accompanies spin-down results in the NS collapsing into a BH before all of its rotational energy is released.

Nonetheless, there are several mechanisms to extract rotational energy from the indefinitely stable magnetar remnant.
There is plenty literature on the subject that suggests that rotational energy input from a stable magnetar could enhance kilonova emission. The emission is still red in color and peaks on a timescale of 1 to 2 weeks, but the luminosity is greatly enhanced compared to the radioactive case, with peak magnitudes of K $\approx$ 18- 20

* Enhancing from free neutrons

In addition to the blue and red components, recent NS-NS merger simulations show that a small fraction of the dynamical ejecta (typically a few percent, or about 1E-4sm) expands sufficiently rapidly that the neutrons do not have time to be captured into nuclei (Bauswein et al., 2013a). This fast expanding matter, which reaches asymptotic velocities v about 0.4-0.5 c, originates from the shock- heated interface between the merging stars and resides on the outermost layers of the polar ejecta. This `neutron skin' can super-heat the outer layers of the ejecta, enhancing the early kilonova emission (Metzger et al. 2015; Lippuner \& Roberts 2015).

\end{comment}

Tanvir \& Metzger

Later that year, \citet{2013Natur.500..547T} and \citet{2013ApJ...774L..23B} presented evidence for excess infrared emission following the short GRB 130603B on a timescale of about one week using the Hubble Space Telescope. If confirmed by future observations, this discovery would be the first evidence directly relating NS mergers to short GRBs, and hence to the direct production of r-process nuclei.

Rate of GRBs from NS-NS mergers is low, less than once per year all-sky. (e.g. \citet{2012ApJ...746...48M})
We should not expect the first --or even the first several dozen-- GW chirps from NS-NS/BH-NS mergers to be accompanied by a GRB.

Population synthesis models of field binaries predict GW detection rates of NS-NS/BH-NS mergers of about 0.2-300 per year, 
once Advanced LIGO/Virgo reach their full design sensitivities near the end of this decade (e.g. \citet{2010CQGra..27q3001A, 2015ApJ...806..263D}).
Empirical rates based on observed binary pulsar systems in our galaxy predict a comparable range, 
with a best bet rate of about 8 NS-NS mergers per year (\citet{2004ApJ...601L.179K, 2015ApJ...815...67K}).

\textcolor{red}{From here on, this is brought from the toros section}

Black Hole-Neutron Star (BH-NS) or Binary Neutron Stars (BNS) mergers are among the expected events detectable by the LVC. 
These highly energetic events will emit GW radiation in the frequency range of LIGO and Virgo sensitivity, strong enough to be detected up to a few hundreds Mpc of distance.
The precise maximum detection distance depends mainly of the masses involved in the merger, as well as other geometrical and spin parameters, but it sits at around 400 Mpc.

BNS and BH-NS mergers have long been proposed as the process leading to short-hard gamma-ray bursts (SGRBs) 
(\citet{1989Natur.340..126E, 1992ApJ...395L..83N}), but unfortunately this emission is beamed and thus can only be observed in a small fraction of the events.

Mergers with NS are also predicted to be accompanied by a more isotropic EM counterpart, commonly known as a `Kilonova'. Kilonovae are day to week-long thermal, supernova-like transients, which are powered by the radioactive decay of heavy, neutron-rich elements synthesized in the expanding merger ejecta (\citet{1998ApJ...507L..59L}). 

%Lattimer \& Schramm in 1974, were the first to propose a BH-NS merger as a suitable environment for the r-process and its radiation emission.

%Needless to say, is that Kilonovas are an ideal counterpart to the LIGO observations.
%We detail the reasons in the following paragraphs.

Kilonova emission is an ideal EM counterpart to the LIGO observations for the reasons we summarize in the following paragraphs.

As previously said, unlike SGRBs, Kilonova emission is isotropic. 
Even though short GRBs emission, is also present during the BNS merger, the r-process emission in the jet and other merger neutron ejecta, is fairly isotropic.
The chances to detect the GRB jet are very limited by the collimation of the jet and our line of sight, but r-process radiation is not. 

The Kilonovae are bright.
It was based on their derived peak luminosities, of approximately 1,000 times brighter than a nova, that Metzger et al. (2010) first introduced the term `kilonova' to describe this EM counterparts.

Another fundamental element that the multi-messenger astronomy contributes with,
is the identification of host galaxies.
The inference of the distance to the GW event using redshift of host galaxy will greatly reduce degeneracy in the GW parameter estimation,
especially of the binary inclination with respect to the line of sight.
It will also give a better estimate of the energies involved in the merger.
Other interesting environment properties can be derived from the Kilonova detection, like age of the stellar population and possible displacements due to SN birth kicks.

But most importantly, the merger of a binary system involving a NS is very complex and several kind of factors can effect the radiation pattern and light-curve of the Kilonova as well as the GRW waveform. 
The optical light curve can serve as a probe into the core and shed light to the intricacies and details of the merge process.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			TOROS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The TOROS Project}

In 2011, scientists from the Center for Gravitational Wave Astronomy (CGWA) at 
The University of Texas at Brownsville (UTB) 
and the Observatorio Astronomico de Cordoba (OAC) and Instituto de Astronomia Teorica y Experimental (IATE) (the last two in Argentina)
established the TOROS project (\citet{2014EAS....67..357B})
to scan likely areas of the localization uncertainty sky map of the GW trigger, looking for possible optical counterparts.
%to respond to the LVC GW triggers with a wide field search for possible optical counterparts in likely areas of the localization uncertainty sky map.

%Motivated by complementing the LIGO observations in the electromagnetic (EM) side, Dr. Mario Diaz from UT RGV founded the TOROS project. TOROS (the Transient Optical Robotic Observatory of the South), has the main goal of scanning the uncertainty region of the LIGO localization map for GW events, with a wide field telescope and a large CCD pixel camera, searching for EM transients candidates for counterparts for such GW event.

TOROS stands for Transient Optical Robotic Observatory of the South,
and its original project consisted in the construction of an observatory site in Cordon Macon,
a mountain top at 4637 m above sea level, in the Andes mountain range in the north of Argentina.

Cordon Macon is a location with high quality seeing and excellent photometric quality.
The mean and median of the seeing measurements obtained at Macon are 0.70'' and 0.55'', respectively (\citet{2009BAAA...52..285R}). 
Several sites within the area around Cordon Macon were considered for the location of the European Extremely Large Telescope, including a site on the Macon Ridge itself.
%It will also link the network of observatories to the sky in the Southern hemisphere.

The proposed TOROS telescope would have a 0.6 m aperture and a 9.85 sq. deg. field of view.
When fully operational it is planned to have three basic modes of operation:
follow up of GW triggers; 
follow up of gamma-ray burst triggers from Fermi, Swift, and other missions; 
and baseline imaging of the entire surveyable area.

It is also included in the full project the inclusion of a data reduction and processing pipeline for transient detection, as well as a database for the dissemination of catalogs and triggers.

While the original project remains on hold awaiting for proper financing of the facility, several other institutions showed interest to participate as well.
This broadened the TOROS project into a wider collaboration of telescopes instead of the single telescope in Argentina that was originally envisioned.

The collaboration has now partners in Mexico, and the Gemini spectrograph as well as the telescopes in Chile and Cordoba previously mentioned. \textcolor{red}{Use this paragraph to include all the participating institutions}

Whether it be the original design or the new dynamic proposed by the enlargement of the collaboration, the interesting targets to TOROS remain to be mergers with at least one Neutron Star (NS), because of its several radiation messengers.



\begin{comment}

THIS ALL IS INFO ABOUT GRBs

%In physics, GW detection could provide information about strong-field gravitation, the untested domain of strongly curved space where Newtonian gravitation is no longer even a poor approximation. In astrophysics, the sources of GWs that LIGO might detect include binary NSs (like PSR 1913 + 16 but much later in their evolution); binary systems where a black hole (BH) replaces one or both of the NSs; a stellar core collapse which triggers a type II supernova; rapidly rotating, non-axisymmetric NSs; and possibly processes in the early universe that produce a stochastic background of GWs [3].

Observational (e.g., Fong et al. 2013) and theoretical (e.g. Eichler et al. 1989, Narayan et al. 1992) evidence suggest a relation between merges with at least one NS and the ``short duration'' class of GRBs (Nakar 2007, Berger 2014). 

For the majority of GW-detected mergers, the jetted GRB emission will be relativistically beamed out of our line of sight.
The off-axis afterglow probably does not provide a promising counterpart for most observers

Blinnikov et al. (1984) and Paczynski (1986) first suggested a connection be- tween NS-NS mergers and GRBs.

\end{comment}


\begin{comment}

Li \& Paczynski (1998, LP98) first showed that the radioactive ejecta from a NS-NS or BH-NS merger provides a source for powering transient emission, in analogy with Type Ia SNe. 
Given the low mass and high velocity of the ejecta from a NS-NS/BH-NS merger, they concluded that the ejecta will become transparent to its own radiation quickly, producing emission which peaks on a timescale of about one day, much faster than for normal SNe (which instead peak on a timescale of weeks or longer).

Freiburghaus et al. (1999) presented the first explicit calculations showing that the ejecta properties extracted from a hydrodynamical simulation of a NS-NS merger (Rosswog et al. 1999) indeed produces abundance patterns in basic accord with the solar system r-process.

In the late 50's Burbidge et al. (1957) and Cameron (1957) had already proposed that approximately half of the elements heavier than iron are synthesized via the capture of neutrons onto lighter seed nuclei (e.g., iron) in a dense neutron-rich environment in which the timescale for neutron capture is shorter than the $\beta$-decay timescale.
Rapid neutron capture process', or r-process for short, 
Despite this mechanism was known for long time, the astrophysical environments in which this happens remained a mystery.
They showed that the radioactive heating rate was relatively insensitive to the precise electron fraction of the ejecta, and they were the first to consider how efficiently the decay products thermalize their energy in the ejecta.

The type of radiation depends on the EOS for the ejecta and its thermodynamical properties. Opacity, nucleon and particle content, pressure, temperature, MHD state.

Li \& Paczynski (1998, LP98) first showed that the radioactive ejecta from a NS-NS or BH-NS merger provides a source for powering transient emission, in analogy with Type Ia SNe. Given the low mass and high velocity of the ejecta from a NS-NS/BH-NS merger, they concluded that the ejecta will become transparent to its own radiation quickly, producing emission which peaks on a timescale of about one day, much faster than for normal SNe (which instead peak on a timescale of weeks or longer).

\end{comment}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%	                     PIPELINE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Building a pipeline software for TOROS}

Since the ultimate goal of the TOROS Project is the robotization of the telescope,
it is important to have in place a software `pipeline' that accompanies the process
at all stages, from receiving the alert to propose new transient candidates.

The whole operation of TOROS processing can be divided in several stages
as in the diagram of figure \ref{fig:flowchart}.

\begin{figure}
\centering
\scalebox{0.8}{
\begin{tikzpicture}[node distance = 2.2cm]
    % Place nodes
    \node [cloud] (ligo) {LVC Alert System};
    \node [cloud, below of=ligo] (robot) {TOROS Alert Robot};
    \node [xshift=-3cm, left of=robot] (collabx) {\ldots};
    \node [xshift=3cm, right of=robot] (collaby) {\ldots};
    \node [block, below of=robot] (skymap) {Retrieve Skymap};
    \node [block, below of=skymap] (targets) {Target Selection (Scheduler)};
    \node [block, below of=targets] (broker) {Broker Website};
    \node [obse, below of=broker] (obsx) {Observatory X};
    \node [obse, left of=obsx, xshift=-1.5cm, yshift=0.5cm] (obsy) {Observatory Y};
    \node [below of=obsy] (ldots) {\ldots};
    \node [block, below of=obsx] (images) {Take Images \& Data Reduction};
    \node [block, right of=images, xshift=8em] (refimages) {A posteriori Images \& Data Reduction};
    \node[block, below of=refimages] (align) {Alignment};
    \node [block, below of=images] (dia) {Difference Image Analysis};
    \node [block, below of=dia] (realbogus) {Real/Bogus ML};
    \node [block, below of=realbogus] (science) {Science};
    % Draw edges
    \path [line] (ligo) -- (robot);
    \path [line] (ligo) -- (collabx);
    \path [line] (ligo) -- (collaby);
    \path [line] (robot) -- (skymap);
    \path [line] (skymap) -- (targets);
    \path [line] (targets) -- (broker);
    \path [line] (broker) -- (obsx);
    \path [line] (broker) -- (obsy);
    \path [line] (obsy) -- (ldots);
    \path [line] (obsx) -- (images);
    \path [line] (obsx) to[out=0, in=90] (refimages);
    \path [line] (images) -- (dia);
    \path [line] (refimages) -- (align);
    \path [line] (align) -- (dia);
    \path [line] (dia) -- (realbogus);
    \path [line] (realbogus) -- (science);
\end{tikzpicture}
}
\caption{The pipeline flowchart.}
\label{fig:flowchart}
\end{figure}

The pipeline is written entirely in Python, following the latest trend in Astronomy.
We used popular Python packages like numpy, scipy, astropy and other when necessary.
In the case of aligning images and performing image subtraction, I developed tow Python modules
specific to do that, since there were no existing python modules with that functionality at the time of this writing.

In the following sections, I explain the different components of the pipeline diagram.

\section{TOROS Alert Robot}

The first step of the process starts with the alert receiver robot.

The alert receiver is hosted in a virtual machine server provided by UTRGV IT Services.
It is a Python script that runs uninterruptedly waiting for a signal from the 
Gamma-Ray burst Coordinates Network (GCN) and the Transient Astronomy Network (TAN),
a service of NASA delivered on a specific port reserved for this purpose.

The GCN/TAN network is a distribution network of transient events notices dependent on Goddard NASA.
As its name suggest it was primarily intended for the distribution of GRBs but also other transient notices
from Fermi, Swift and other spacecrafts to the rest of the Astronomy community. 
Most notices are sent in real-time, while the event is still ongoing, 
others are delayed due to telemetry down-link delays.

The subsequent reports of follow-up observations made by ground-based observers, are done by submitting circulars to that same site.
This makes the GCN/TAN network {\em ``a one-stop shopping network for follow-up sites and GRB and transient researchers.''}

The LIGO-Virgo Collaboration makes use of the GCN network to disseminate the event
notices to the participating observatories searching for EM counterparts.

The notice comes in the form of a Virtual Observatory Event (VOE) file,
and it is distributed as a message to predefined static IPs and ports,
using the VOEvent Transport Protocol.

\textcolor{blue}{VOEvent is an IVOA Recommendation -- that is, it has been adopted as an international standard. As with many other IVOA standards, VOEvent is based on XML, the Extensible Markup Language [9]. XML is ubiquitous in worldwide web technologies and simply provides a structured way to build a nested hierarchy of elements, to attach attributes to those elements, and to assign values to each. An additional constraint on many IVOA standards, including VOEvent, is a schema to apply rules on the arrangement and numbers of each element and attribute and on their allowed values. XML Schema [10] can be an often-entertaining technology for the designers of a standard. Providing a battle-hardened VOEvent schema [11] is a priority of the VOEvent v2.0 development effort. A well-crafted schema permits the validation of documents (in this case VOEvent messages, also referred to as ``packets'') against the requirements of the standard, and can even be used to automatically create software to parse such messages.}

The VOEvent Transport Protocol is a simple TCP-based protocol for transporting VOEvent messages from authors, through brokers, to subscribers.

VOEvent is the International Virtual Observatory Alliance (IVOA) recommended mechanism for describing astronomical transients.
According to its main website \footnote{\href{http://wiki.ivoa.net/twiki/bin/view/IVOA/IvoaVOEvent}{http://wiki.ivoa.net/twiki/bin/view/IVOA/IvoaVOEvent}},
it is an XML file notice that ``{\em defines the content and meaning of a standard information packet for representing, transmitting, publishing and archiving information about a transient celestial event, with the implication that timely follow-up is of interest.}'' 

In our case, we registered two static IPs with GCN, one in Texas at UT RGV and another one for Cordoba in Argentina at IATE Institute.
Only the one in Texas is functional at the moment, while the one in Cordoba is receiving but has problems sending out emails.

The VOEvent is received by a continuously running script that listens on the specific port and creates an alert email involving the heads and some staff at each TOROS partner.

The listening is done mainly by the PyGCN module developed by Leo Singer, which handles the reception GCN notices from LVC. The rest of email sending is done by usual Python tools for that task.

Right now, the script does a minimum process to deliver the XML body of the VOEvent by email to predetermined recipients.
Future improvements on this side should include the automatic download of the skymaps
to be attached to the email along with the VO Event notice.

It could also pre-process the skymap to extract most likely galaxy hosts for observing targets.

Right now, this is done on a separate script that requires human intervention.

\section{Target Selection}

As mentioned before, the target selection is done with a separate script.
This script makes use of the sky-map provided in the alert notice and the 
Gravitational Waves Galaxy Catalog (GWGGC) (\citet{2011CQGra..28h5016W})

The White's catalog is a homogeneous list of 53,255 galaxies within 100Mpc.
It is a compilation from 4 different catalogs: an updated version of the Tully Nearby Galaxy Catalog,
the Catalog of Neighboring Galaxies, the V8k catalogue and HyperLEDA.

GWGC contains information on sky position, distance, blue magnitude, major and minor diameters, position angle, and galaxy type.
Also included in the catalog are 150 Milky Way globular clusters.

The authors claim that GWGC is more complete --within 100 Mpc-- than other catalogs,
due to their use of more up-to-date input catalogs
and the fact that they don't make a blue luminosity cut.

%Another catalog along these lines is the Glade GW Catalog. Glade Catalog has xxxx galaxies listed, this many more than CWGC and extends up to XX Mpc.
%Nonetheless many distances are inferred by Machine Learning Methods, and completitude of the Catalog... bla bla

The target selection for our optical search is based on three main criteria: 
the localization (un)certainty on the target pixel in the all-sky map given by LIGO at the time of the alert,
the visibility of the targets at the moment of the event by our several telescopes, 
and several filter cuts on distance, blue luminosity and apparent magnitude.

This marriage between GW and Optical parameters of observability ensures the targets are visible at each telescope site, 
and that they have some significant probability of being the host.
The list of filter cuts are summarized in table \ref{obsfilters}.

\begin{table}
\centering
\begin{tabular}{|l|c|}
  \hline
 Parameter & Limit value \\ \hline
Observability from location & $30^{\circ} > \delta > -70^{\circ}$ for EABA \\ \hline
Apparent Magnitude & $B \le 21$ mag \\ \hline
Distance  & $D < 60$ Mpc \\ \hline
Absolute Magnitude & $MB \le -21$ mag \\ \hline
\end{tabular}
\caption{Parameter Cuts}
\label{obsfilters}
\end{table}


\section{The Broker}

Once the list of targets is done, we need to communicate the targets to each telescope.
This is done through a broker website written in Python using the Django\footnote{\url{https://www.djangoproject.com}} web framework (see figure \ref{fig:brokerhead}).
Each telescope representative has assigned a username and password to access a website hosted on UTRGV servers.
This website has a simple interface of tables for each observatory and a list of targets observable from each location, obtained by the target selection method on the previous step.

Each telescope admin then selects targets from the list, to reserve them for his or her observatory (see figure \ref{fig:brokerdetail}). 
The website enforces that the list of targets be unique and that no two observatories are observing the same target.
It does so, by ignoring targets previously selected by others on the query.

Each observatory then carries the observations for the successive nights and file a report of the observations when these are done.

The website can also output a circular draft of all the targets observed by each telescope to be submitted to the GCN/TAN website for the rest of the community.

\begin{figure}
\centering
\includegraphics[scale=0.2]{figures/broker_header}
\caption{A portion of the Broker website with target assignments.}
\label{fig:brokerhead}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.2]{figures/broker_obsdetail}
\caption{An example of a detail table of targets assigned to the Mamalluca Observatory.}
\label{fig:brokerdetail}
\end{figure}

For the web pages developed to support the collaboration, we used the popular Python web framework Django
and a light database on Sqlite 3.

Sqlite provides a lightweight database solution that does not require complex server-client operations, and it stores all data in a simple file.
Thus, the database is easy to browse and modify.
The database handles information for the GW Galaxy Catalog, the user information as well as permissions and login information,
Observatories data.

\section{Data Reduction}

This step in the pipeline is specific to the data processing techniques used in each observatory.
For the purpose of testing the capabilities and efficiency of the rest of  the pipeline we conducted a test run on an image set.

The following stages of the pipeline deal with the specific analysis to identify candidates to optical counterparts of GW.

The first part deals with the Difference Image Analysis.
For that two images, one taken at the epoch of interest and another one used as a reference. Ideally, the reference is an archive image or a stack of several others to improve signal to noise ratio, cosmic rays and other contaminants on the image.

In the case for our campaign for O1, we had to use a-posteriori references taken a few months after the event.

Before performing the subtraction, both images have to be aligned pixel by pixel.
Software to perform the alignments was done using a method described in section \ref{astroalign_section}.
I describe there a method based on asterism matching inspired in astrometry.net.

The subtraction methods are explained in section \ref{ois_section}.
Several algorithms are explained in the literature with a wide range of methods, from Fourier Transform, to PSF matching to using Information Theory.
Some of them are explained and implemented in a Python module named `ois' developed by me for this project.

The Difference Image Analysis and Machine Learning Real-Bogus classifier parts are tested over an image data set collected by CSTAR.
The CSTAR image set is a high cadence set of images taken in the winter of 2010 in Antarctica, the South Pole. 
It comprises 6 months of data with an median cadence of 42 s.



\subsection{The CSTAR image-set preparation}

Since the amount of data is so large, for the purpose of training, we created a subset of 626 images, 
with a cadence of about an hour during the best seeing month of June (May 31st to June 30th, 2010). 
The subset was named `cstar\_june\_selection'. 
The first 10 images of this set (named cstar\_june\_01) is used for training purposes and the rest can be used to search for transients. 

The images are mostly clean, that is they were bias and flat corrected.
Nevertheless, the images suffer from `bleeding' even though they have low exposure time.
This bleeding is very significative for bright stars and less so for dimmer stars but still present nonetheless.

The bled stars were covered with the median and a separate mask was created for the covered pixels for future reference.
This pixel mask also includes defective pixels (dead lines and columns in the CCD).

The date-time information on the header was also updated according to \textcolor{red}{[ref]}.

For each of these images, we aligned a reference image with it using the package `astroalign' (see section astroalign) 
and also performed a image subtraction using the delta basis method on a 4 by 4 grid.

\section{Optimal Subtraction}

\section{Training a Real/Bogus Classifier Agent}

The subtraction techniques are very effective at  modeling PSF differences, nevertheless there are many defects left behind after a subtraction. 
This is also a well known issue in the difference image analysis. 
The bogus residual sources arise primarily from PSF mismatch and misalignments of the images.
Several examples of this kind are shown on figure \ref{fig:subtraction_errors}

\begin{figure}
\centering
\includegraphics[scale=0.4]{figures/subtraction_error}
\caption{Some examples of subtraction errors due to misalignment and wrong PSF matching for an idealized object with a Gaussian profile.
The top row shows typical morphology of residuals for different types of mimatches.
The bottom row shows cross sections of the top row showing the object profiles in blue and green and the subtraction in red.
First column corresponds to a displacement of the object with respect to the reference. 
The second column represents objects with different PSF.
The third column is the more typical kind of bogus residual, a combination of displacement and PSF mismatch.}
\label{fig:subtraction_errors}
\end{figure}

These defects can easily confuse algorithms of source detection like SExtractor or similar that relies on excess of flux over the background.
For that, it is needed to have a computerized agent capable of discriminating bogus sources from real transients on the subtracted image. 

This is the task of a Machine Learning (ML) agent trained for that purpose. The real bogus classifier, as it is named in the literature 
relies on --mostly morphological-- features to perform the classification.

Machine Learning is such an extensive and intensive area of research with many applications in many fields.

Since the ML field is so wide, to conduct a ML experiment one must make a few decisions. Even most importantly than the particular algorithm, 
for which there are hundreds and modifications are being published all the time, it's the data that drives the efficiency of the method.

As the saying goes:

\begin{quotation}
Big data will beat a good algorithm \textcolor{red}{Find exact quote and author}
\end{quotation}

For our main test, I decide to train a Random Forest ML algorithm on a training set developed especially for this.

The Random Forest algorithm is an `ensemble' method. Meaning it is a collection of other methods whose results will be averaged over somehow.

In this case, a Random Forest is an `ensemble' of Decision Trees. A Decision Tree is basically a tree of nodes. Each node represent a bifurcation based on one feature. The features and branching threshold on each node are chosen maximizing the expected information gain (or entropy loss) on the training set. That is, how well the bifurcation separates the training data for each class.

Random Forest bootstraps the data so that each subset of data will train a Decision Tree on a random subset of the features. After all Decision Trees are trained this way, the collection of Trees will give the final classification.

A single Decision Tree suffers of great variance, even for big amounts of data. The bifurcations on the greedy algorithm are naturally very dependent on the training set. A small variation on it may create a complete different tree. Random Forest reduces this variance by averaging over many trees. This also creates more realistic and fuzzy class boundaries on the feature space.

On the next section I explain how the training data was prepared.

\section{Training Data}

The main challenge to generate training data is the great unbalance between bogus sources due to imperfect subtraction and actual real transients.

On a typical image, the number of bogus sources can be of a hundred, and the rate of real transients can be only a handful. 

The Machine Learning problem becomes one of `Information Retrieval'. We are mainly interested in only one class, the real transients, and we need to retrieve samples of that class from a sea of bogus transients.

In a situation like that, a very unbalanced training set can bring about spurious results. As an example, imagine a training set with 90 bogus and 10 reals. The Zero Rule Classifier --that is the classifier that classifies everything as bogus-- would have a 90\% Precision and 100\% Recall for the bogus class. An unbalanced training set could also create classifiers with large variance due to the small set of real samples.

`Recall' measures the fraction of samples of the relevant class that were retrieved by the classifier out of the total number of reals in the set.
The class we are mainly interested in for the Recall is that of the real transient examples.

To generate a balanced training set with comparable amounts of reals and bogus, I generate reals by selecting sources on an image and erasing them on the reference. That way, after a subtraction, those sources will appear as transient events, that is, objects in the image that don't have a corresponding object on the reference.

The image set used for this purpose is CSTAR, but any other set will also perform similarly.

The advantage of this method, compared to other methods like injecting fake sources, is that the `transients' obtained this way will have all the particular characteristics of the CCD and instrument from the image set in which we are interested to work. It will also have the characteristics of the subtraction method imperfections, but this is not exclusive to this method.

The `bogus' set is also collected at the same time along with the `real' set.

To have equal representation of sources of different magnitudes, the sources are first binned into 10 bins of \textcolor{red}{magnitude/flux?} and taken from different regions of the CCD.
We partition the image in a 4 by 4 grid and we select one star from each region and we do so for each magnitude bin. \textcolor{red}{explain better!!!}

\section{The Classifier}

As previously said, we trained a Random Forest classifier based on 7,624 examples of fabricated transients (as described in section data) and 7,624 bogus picked at random from the subtraction images. This totals 15,248 samples for training and validation.

The features used for this classifier were selected from the popular source extractor software SExtractor (\citet{1996A&AS..117..393B}). We chose the features that had relation to the morphology of the source and some other features derived from them.
The whole list is presented in table \ref{mlfeatures}.

Several scores about the performance of the classifier on the training data are condensed in the scores table (\ref{mlscores}).

\begin{table}
\centering
\begin{tabular}{|l| >{\itshape}l|}
  \hline
  x2 & Sum of the x squared values $\sum x^2 $ \\ \hline
  y2 & Sum of the y squared values $\sum y^2 $\\ \hline
  xy & Sum of the product of x and y values $\sum xy $\\ \hline
  cxx, cyy, cxy & Same as x2, y2 and xy in the convolved image  \\ \hline
  a, b, theta & semi-major axis, semi-minor axis and orientation of the best ellipse fit to the object \\ \hline
  mag\_aper & Aperture magnitude of the object in the subtraction image \\ \hline     magerr\_aper & Error of mag\_aper \\ \hline
  flux\_aper & Aperture flux in counts of the object in the subtraction image \\ \hline
  fluxerr\_aper & Error of flux\_aper \\ \hline
%threshold & \\ \hline
flux\_max & Maximum value of the flux \\ \hline
fwhm & Full width at half maximum \\ \hline
deltax & Width in pixels of the object (X\_MAX - X\_MIN) \\ \hline
deltay & Height in pixels of the object (Y\_MAX - Y\_MIN) \\ \hline
ratio & $\min$(deltax, deltay)/ $\max$(deltax,deltay,1) \\ \hline
roundness & a/b\\ \hline
peak\_centroid & Distance in pixels from the pixel with highest count to the centroid of the object \\ \hline
\end{tabular}
\caption{Random Forest Features}
\label{mlfeatures}
\end{table}

\begin{table}
\centering
\begin{tabular}{| >{\itshape}l | l |}
  \hline
  accuracy & 0.9935 \\ \hline
  precision & 0.9956 \\ \hline
  recall & 0.9915 \\ \hline
  F measure & 0.9936 \\ \hline
\end{tabular}
\caption{Random Forest Scores}
\label{mlscores}
\end{table}

On the training data, the performance is quite good, with all indicators scoring above 99 percent.

In the confusion matrix (table \ref{mlconfusionmatrix}) we see that only 65 out of 7,624 of the reals were mis-classified as bogus, and only 33 bogus out of the 7,624 were mis-classified as reals. These very low numbers explain the very high performance scores of the classifier.

\begin{table}
\centering
\begin{tabular}{ l|c|c| }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{real}
 & \multicolumn{1}{c}{bogus} \\
\cline{2-3}
{\it Classified as} real & 7591 & 33 \\
\cline{2-3}
{\it Classified as} bogus & 65 & 7559 \\
\cline{2-3}
\end{tabular}
\caption{Confusion Matrix}
\label{mlconfusionmatrix}
\end{table}

\textcolor{red}{TO DO: Add analysis of feature importance}

\section{Testing the classifier on real data}

Once we have trained our classifier with training data, we wanted to also test it in a more real situation. For that we apply the classifier to the rest of the cstar\_june\_selection data set in search of actual transients of the image.

The Random Forest classifier will not only predict the class, but can also output a probability for that class.

Setting the probability to 0.9, the classifier returns the most likely transient events. The rate of real transient in the images is of about 15 per image for this probability threshold.

Some examples of these are shown in figure ??.

For very faint events or events that comprise very few pixels in the image, we can have additional filters that weed them out. Although, some of this could be of astronomical interest and discarding them could result in its loss.

\section{Results}

We created a pipeline that is capable of responding to alerts sent by LVC.
It will do so by parsing the VOEvent file for the alert, capturing metadata of the alert, download the skymaps for the localization uncertainty
and creating targets for the telescopes, based on criteria of potential host galaxy, visibility at the time of the event and probability of hosting the event.

The mock run on CSTAR data showed that the difference image analysis together with Real-Bogus trained on the same data set 
can be used to select possible candidates of counterpart transients.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			O1 Observations
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Observations for GW150914 Optical Counterparts}

On April 2014, TOROS signed a Memorandum Of Understanding (MOU) with the LIGO Virgo Collaboration, in order to participate 
in a program to perform follow-up observations of GW candidate events with the benefit of access to LVC proprietary information.

The MOU signing was a very important step that allowed TOROS to participate in the O1 LIGO campaign with positive results.
The MOU allowed TOROS to receive the LIGO alerts, which were private and confidential at the time of O1 and O2, 
and to be part of a publication as part of a broader collaboration with other institutions for the electromagnetic counterpart search of the first announced GW ever, namely GW150914.

The O1 campaign was a 4 month run, officially started on September 18, 2015 and ended on January 12, 2016.
Two detectors were operational during the whole run, the H1-L1 network, operating with a BNS range of about 60 Mpc.
The Virgo detector was being upgraded during O1 so it was not part of the operating detectors during the run.
During O1, 3 alerts were issued for 3 different events.

The first one was from an event detected by LIGO instruments on September 14, 2015 at 09:50:45 UTC (\citet{2016PhRvL.116f1102A}).
The event was designated after confirmation, with the code GW150914.
This was also the first confirmed Binary BH merger ever detected through its gravitational waves.
TOROS observed several regions of the sky during the night that we received the alert.

GW150914 reached the LIGO instruments with a significance greater than 5.3$\sigma$
and a combined signal to noise ratio (SNR) of 23.7.
The GW signal matched with a template for a binary with primary mass of $36.2^{+5.2}_{-3.8} M_{\odot}$ 
and a secondary mass of $29.1^{+3.7}_{-4.4} M_{\odot}$.
The final mass of the system after merger $62.3^{+3.7}_{-3.1} M_{\odot}$ with a final spin $0.68^{+0.05}_{0.06}$,
that represents a total radiated energy of $3.0^{+0.5}_{-0.4} M_{\odot} c^2$.
The luminosity distance to the merger is $420^{+150}_{-180}$Mpc, or a redshift $z=0.09^{+0.03}_{-0.04}$.

The second one, LVT151012 (\citet{2016PhRvX...6d1015A}) did not cross the 5$\sigma$ significance threshold,
but, according to the authors ``it is more likely to have resulted from a gravitational-wave signal than from an instrumental or environmental noise transient'' .
LVT151012 has a significance of $1.7 \sigma$ and a combined SNR of 9.7.
If it is a result of a BBH merger, it would be a system with 23 and 13 $M_{\odot}$.

The third and last confirmed event for O1, GW151226 (\citet{2016PhRvL.116x1103A}), had a significance over $5.3 \sigma$ and a combined SNR of 13.0.
The GW signal was consistent with a template match for a binary system with masses 14.2 and 7.5 $M_{\odot}$.
The final mass of the merger is $20.8 M_{\odot}$, which means that $1 M_{\odot}$ was radiated away as gravitational radiation.

TOROS did not participate in the optical search for LVT151012 or GW151226.
The remaining of this chapter refer to the observation campaign for the GW150914 event follow-up search and its results.

\section{GW150914}

As mentioned before, GW150914 was detected on September 14, 2015, that is 4 days before O1 officially began (see figure \ref{fig:GW150914ligosignal}).
Because LIGO was on the engineering run E7 at the moment of the detection, the alert was not sent to MOU observatories until two days after.
On the night of September 16, 2015, the LIGO alert arrived through the TOROS alert receiver system.
Despite the premature arrival of the alert, TOROS could scan a region of the LIGO localization map 
and contribute to the EM counterpart search. 

\begin{figure}
\centering
\includegraphics[scale=0.5]{figures/GW150914detection}
\caption{GW150914 event observed by the LIGO Hanford (H1, left column panels) and Livingston (L1, right column panels) detectors. 
Top row is the strain signal. Second row is the GW strain projected onto each detector in the 35--350 Hz band. 
Solid lines show a numerical relativity waveform for a system with parameters consistent with those recovered from GW150914. 
Third row: Residuals after subtracting the filtered numerical relativity waveform from the filtered detector time series. 
Bottom row: A time frequency representation of the strain data.}
\label{fig:GW150914ligosignal}
\end{figure}


Besides LIGO and Virgo Collaborations, other 24 institutions participated in the optical counterpart search for the GW150914 event along with TOROS.
These are detailed in table \ref{gw150914participants}.

\begin{table}
\centering
\begin{tabular}{|l|c|}
\hline
Institution name & Band \\ \hline
The LIGO Scientific Collaboration & GW \\
The Virgo Collaboration & GW \\
The Australian Square Kilometer Array Pathfinder (ASKAP) Collaboration & Radio \\
The Bootes Collaboration & Optical \\
The Dark Energy Survey And The Dark Energy Camera GW-EM Collaborations & Optical/NIR \\
The Fermi GBM Collaboration & $\gamma$-rays \\
The Fermi LAT Collaboration & $\gamma$-rays \\
The Gravitational Wave Inaf Team (Grawita) & Optical/NIR \\
The Integral Collaboration &  $\gamma$-rays \\
The Intermediate Palomar Transient Factory (iPTF) Collaboration & Optical \\
The Interplanetary Network & $\gamma$-rays \\
The J-Gem Collaboration & Optical \\
The La Silla-Quest Survey & Optical \\
The Liverpool Telescope Collaboration & Optical \\
The Low Frequency Array (LOFAR) Collaboration & Radio \\
The Master Collaboration & Optical \\
The Maxi Collaboration & X-ray \\
The Murchison Wide-field Array (MWA) Collaboration & Radio \\
The Pan-STARRS Collaboration & Optical \\
The PESSTO Collaboration & Optical \\
The Pi Of The Sky Collaboration & Optical \\
The SkyMapper Collaboration & Optical \\
The Swift Collaboration & $\gamma$-rays \\
The Tarot, Zadko, Algerian National Observatory, And C2PU Collaboration & Optical \\
The TOROS Collaboration & Optical \\
The Vista Collaboration & Optical and Infrared \\ 
\hline
\end{tabular}
\caption{Participating Institutions in the GW150914 EM Counterpart Search}
\label{gw150914participants}
\end{table}

%The search did not show up any transient associated with the event,

We conducted unfiltered CCD observations (0.35--1$\mu$m) with the 1.5-m telescope 
at Estacion Astronomica Bosque Alegre (EABA) telescope in Cordoba, Argentina.


Because of the unexpected timing of the event, the alert was received 2 days later, and our observations started about 2.5 days after the alarm was received by LIGO.

This unexpected detection --observed four days before the first scientific run of the detectors was scheduled to start-- constituted the first detection of the merger of a binary black hole (BBH) system and the first direct detection of gravitational waves. Due to the unexpected timing of the event, LVC provided spatial location information two days later, in the form of probability sky maps via a private GCN circular (Singer 2015, GCN\#18330). TOROS was one of 25 teams that participated in the search for an electromagnetic counterpart search in the southern hemisphere.

On 2015 September 16, the LIGO Virgo Collaboration (LVC) provided two all-sky localization probability maps for the event, based on them.
Both, the coherent Wave Burst (cWB; Klimenko et al. 2016) and the Omicron+LALInference Burst (oLIB; Lynch et al. 2015) search for unmodeled signals. The first one, a rapid localization analysis just searches for coherent power across both detectors while the second one, more refined, assumes a Sine-Gaussian content. The maps provided initial spatial localization of 50\% and 90\% confidence regions encompassing about 200 and 750 square degrees, respectively (Singer 2015, GCN\#18330).

We started our imaging campaign immediately after
receiving, on the night of 2015 September 16, utilizing the
cWB map. Additional observations were obtained the
following night, and a second epoch of imaging was acquired on 2015 December 5 \& 6. We used an Apogee Alta
U9 camera with a field of view (FoV) of 12.'7 $\times$ 8.'5 and
an effective plate scale of 0.''75pix after 3 $\times$ 3 binning. Since we wished to maximize our sensitivity, we conducted unfiltered (``white light'') observations spanning 0.35 < $\lambda/\mu$m < 1. We obtained individual exposures of 60 s with a median seeing (FWHM) of (2.8 $\pm$ 0.6)''. 
We typically obtained 10 images per field, reaching 5$\sigma$ limiting magnitudes of r = 21.7 $\pm$ 0.3 mag.

Despite the little area covered by TOROS, the O1 campaign allowed the collaboration to test the detection and response systems to the alerts.

\begin{table}
\centering
\begin{tabular}{|*{7}{c|}}
  \hline
 Date & GWGC & RA & Dec & $t_{exp}$ & Tile & D \\ 
 (Local Time) & ID & [Deg] & [Deg] & [s] & Number & [Mpc] \\ \hline
2015-09-16 & IC1933 & 51.416101 & -52.78547 & 600 & 1,2,3,4 & 17.45 \\
2015-09-16 & NGC1529 & 61.833301 & -62.89993 & 600 & 5,6,7,8 & 54.76 \\
2015-09-16 & IC2038 & 62.225246 & -55.99074 & 600 & 9,10,11,12 & 7.00 \\
2015-09-16 & IC2039 & 62.259901 & -56.01172 & 600 & 9,10,11,12 & 7.63 \\
2015-09-17 & ESO058-018 & 102.593850 & -71.03123 & 1020 & 13 & 52.23 \\
2015-09-17 & ESO084-015 & 65.550449 & -63.61097 & 1140 & 14 & 14.99 \\
2015-09-17 & ESO119-005 & 72.072451 & -60.29376 & 1080 & 15 & 9.73 \\
2015-09-17 & NGC1559 & 64.398901 & -62.78358 & 900 & 16 & 12.59 \\
2015-09-17 & PGC016318 & 73.728898 & -61.56747 & 1020 & 17 & 9.54 \\
2015-09-17 & PGC269445 & 100.209150 & -71.33026 & 1140 & 18 & 54.83 \\
2015-09-17 & PGC280995 & 96.382499 & -69.15257 & 1140 & 19 & 55.08 \\
2015-09-17 & PGC128075 & 64.859998 & -60.53844 & 720 & 20 & 63.71 \\
2015-09-17 & PGC381152 & 63.584547 & -58.20726 & 1200 & 21 & 13.26 \\
2015-09-17 & PGC075108 & 63.670349 & -58.13199 & 1200 & 21 & 13.29 \\ \hline
\end{tabular}
\caption{Targeted host galaxies}
\label{o1targets}
\end{table}




\begin{comment}

The compact binary coalescence (CBC) search targets gravitational-wave emission from compact-object binaries 
with individual masses from 1$M\odot$ to 99$M\odot$, total mass less than 100$M\odot$, and dimensionless spins up to 0.99.

Sky location is ligo is very poor because it's based mainly on triangulation of detectors.
	Sky error regions are very large (e.g. $\approx$ 850 deg2 for GW150914; Abbott et al. 2016).
	With Virgo and KAGRA and INDIGO will be of of 10-100 square degrees or less (e.g., Fairhurst 2011, Nissanke et al. 2013, Rodriguez et al. 2014). 
	It still greatly exceeds the fields of view of most radio, optical, and X-ray telescopes.

Identifying host galaxies of GW is important. We can know:
	Age of stellar population.
	Displacement due to SN birth kicks.
	Determine distance to GW source. This reduces degeneracies in the GW parameter estimation, especially of the binary inclination with respect to the line of sight.

Based on their derived peak luminosities being approximately one thousand times brighter than a nova, Metzger et al. (2010) first introduced the term `kilonova' to describe the EM counterparts of NS mergers powered by the decay of r-process nuclei

GRB emission is collimated and jetted, so the chances to detect one along a GW are very low.

Observational (e.g., Fong et al. 2013) and theoretical (e.g. Eichler et al. 1989, Narayan et al. 1992) evidence suggest a relation between merges with at least one NS and the ``short duration'' class of GRBs (Nakar 2007, Berger 2014). 

[literal] Short GRBs are commonly believed to be powered by the accretion of a massive remnant disk onto the compact BH or NS remnant following the merger. This is typically expected to occur within seconds of the GW chirp, making their temporal association with the GWs unambiguous (the gamma-ray sky is otherwise quiet).

For the majority of GW-detected mergers, the jetted GRB emission will be relativistically beamed out of our line of sight.
The off-axis afterglow probably does not provide a promising counterpart for most observers

critical four-way connection between kilonovae, short GRBs, GWs from NS-NS/BH-NS mergers, and the astrophysical origin of the r-process nuclei. Metzger et al. (2010)

NS-NS/BH-NS mergers are also predicted to be accompanied by a more isotropic counterpart, commonly known as a `kilonova'. Kilonovae are day to week-long thermal, supernova-like transients, which are powered by the radioactive decay of heavy, neutron-rich elements synthesized in the expanding merger ejecta (Li \& Paczynski 1998). They provide both a robust EM counterpart to the GW chirp, which is expected to accompany a fraction of BH-NS mergers and essentially all NS-NS mergers, as well as a direct probe of the un- known astrophysical origin of the heaviest elements (e.g., Metzger et al. 2010).

The most significant of those is no doubt, the Kilonova emission produced by rapid capturing of neutrons.
Neutron capture has to be faster than the beta decay rate of the neutron and that's why it has to be rapid.
This capture process is called r-process. R is for rapid.
The r-process physics is quite complicated and involves a bunch of stuff, much of which is modeled to certain confidence, 
but many other elements are not well known. Several ingredients to the model are not considered fully. 

Blinnikov et al. (1984) and Paczynski (1986) first suggested a connection between NS-NS mergers and GRBs.

Even prior to the discovery of the first binary pulsar (Hulse \& Taylor 1975), Lattimer \& Schramm (1974, 1976) proposed that the merger of compact star binaries --in particular the collision of BH-NS systems-- could give rise to the r-process by the decompression of highly neutron-rich ejecta (e.g. Meyer 1989). 

As compared to the earlier predictions (e.g. Metzger et al. 2010), these higher opacities push the bolometric light curve to peak later in time (1 week instead of a 1 day timescale), and at a lower luminosity (Barnes \& Kasen, 2013). More importantly, the enormous optical opacity caused by line blanketing moved the spectral peak from optical/UV frequencies to the near-infrared (NIR).

TOROS, the Transient Optical Robotic Observatory of the South, is a collaboration formed to respond to GW events as detected by the LVC.
Its main purpose then is to detect transient events compatible with expected (or not) signatures of events that can give mutual birth to GW and optical triggers.

Being in its early stages of development, and given the new nature of the multi-messenger astronomy, the TOROS team is building up the tools and infrastructure that will make it capable in the future to promptly respond to this alerts.

Several things can enter in consideration for this task, from software development to forging ties with existing observatories. 

My thesis will focus on several challenges in the development of the software infrastructure needed to process the observatory data. 

At the moment of this writing, TOROS Collaboration consists of several astronomical institutions that showed interest in doing a search and possible follow-ups of candidates to interesting events.

At UT Rio Grande Valley, we developed extensive analysis and web code to allow for the interaction between the institutions \textcolor{red}{(just the broker page, really)}. 

\end{comment}

\section{Target Selection}

The LIGO localization regions span several hundred square degrees (see Fig. 1) and vary depending on the algorithm. For instance, the 90\% credible localization area for cWB covers to 310 square degrees while others span up to 750 square degrees (see table 1 in Abbott et al. 2016c). Regardless, all sky maps are consistent with a broad long arc in the Southern hemisphere and a smaller extension in the Northern hemisphere. The algorithm utilized for the CWB estimations produces reasonably accurate maps for BBH signals, but underestimates the extent of high-confidence regions (Essick et al. 2015). As seen in Fig. 1, the adoption of maps from alternative algorithms (not available at the time our observations started) significantly reduces the fraction of the high-confidence region probed by our small FoV.

\begin{figure}
\centering
\includegraphics[scale=0.5]{figures/pointings}
\caption{cWB, LIB, BYST, LALinf Sky-maps re-scaled regions that mark TOROS targets (red dots).}
\label{fig:pointings}
\end{figure}

As mentioned before, the target selection is done with a separate script.
This script makes use of the sky-map provided in the alert notice and the 
Gravitational Waves Galaxy Catalog (GWGGC) (A List of Galaxies for Gravitational Wave Searches, Darren J. White et al, 2011)

The White's catalog is a homogeneous list of 53,255 galaxies within 100Mpc.
It is a compilation from 4 different catalogs: an updated version of the Tully Nearby Galaxy Catalog,
the Catalog of Neighboring Galaxies, the V8k catalogue and HyperLEDA.

GWGC contains information on sky position, distance, blue magnitude, major and minor diameters, position angle, and galaxy type.
Also included in the catalog are 150 Milky Way globular clusters.

The authors claim (ref) that GWGC is more complete --within 100 Mpc-- than other catalogs,
due to their use of more up-to-date input catalogs
and the fact that they don't make a blue luminosity cut.

Another catalog along these lines is the Glade GW Catalog. Glade Catalog has xxxx galaxies listed, this many more than CWGC and extends up to XX Mpc.
Nonetheless many distances are inferred by Machine Learning Methods, and completitude of the Catalog... bla bla

The target selection is based on two main criteria: the localization (un)certainty on the target pixel in the all-sky map given by LIGO at the time of the alert,
and several filter cuts on distance, blue luminosity and apparent magnitude.

This marriage between GW and Optical parameters of observability ensures the targets are visible at each telescope site, and that they have some significant probability of being the host.
The list of filter cuts are summarized in table \ref{obsfilters}.

\begin{table}
\centering
\begin{tabular}{|l|c|}
  \hline
 Parameter & Limit value \\ \hline
Observability from location & $30^{\circ} > \delta > -70^{\circ}$ for EABA \\ \hline
Apparent Magnitude & $B \le 21$ mag \\ \hline
Distance  & $D < 60$ Mpc \\ \hline
Absolute Magnitude & $MB \le -21$ mag \\ \hline
\end{tabular}
\caption{Parameter Cuts}
\label{obsfilters}
\end{table}


\section{Image Reduction}

\section{Results}

The observation campaign for the GW150914 left us with a visit of XX fields and XX targets.
The probability covered was less than 0.01\%.

The TOROS collaboration conducted a prompt search for the electromagnetic counterpart of the 
first gravitational-wave event reported by LIGO using the 1.5-m telescope of Estacion Astrofisica Bosque Alegre (EABA) in Cordoba, Argentina. 
Our search spanned two nights, during which we targeted 21 fields containing nearby (D < 60 Mpc) luminous (MB <  21 mag) 
galaxies with high probabilities of hosting the event. We covered 0.62 square degrees and reached a 5$\sigma$ limiting AB magnitude of r = 21.7.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%			O1 ANALYSIS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Data Analysis for GW150914 Optical Counterparts}


\section{Difference Imaging Analysis}

To search for potential transients on the images taken as described in the last chapter, we performed a difference image analysis (DIA) on them.

Common methods of DIA like HOTPANTS (\citet{2015ascl.soft04004B}) or ISIS use the method developed by \citet{1998ApJ...503..325A}.
The method uses a kernel, combination of 2 or more Gaussians, modulated by a polynomial to match and scale the point-spread-function (PSF) between two epochs.
This leads to difficulties in fitting irregular shaped PSFs that depart considerably from the Gaussian profile.

Our method follows the work of \citet{2008MNRAS.386L..77B} and \citet{2008PASP..120..449M} in a Python implementation of the 
algorithms\footnote{For more information on the package implementation, see section \ref{ois_section}.}.
The method uses a `Dirac delta' basis across the entire frame, so that each pixel in the kernel is fit independently.
With this method there are no free parameters to adjust like with the multi-Gaussian method, so the user does not need to estimate parameters (which can lead to poor PSF matching).
The method uses the information from all the pixels on the image, wether is a background pixel or a source pixel,
so we don't need to select specific stars to take stamps around.
Although using all the pixels in the image gives the advantage of the algorithm run automatically without any input from the user, the use of stamps has some advantages.
The main one being the speed-up calculation, since the optimization is done only on a restricted set of pixels (those of the stamp set) 
and another advantage is that the user can manually exclude bad sources or outliers during the optimization.
A compromise between the two can be met if the program chooses sources automatically like in \citet{2008PASP..120..449M}.
We did not use stamps but it is a planned update to be done in the future.

The optimal kernel, or its coefficients, for the convolution is done by the least-squares method.
Even though the Python module can do a simultaneous background estimation to be subtracted, 
we could see that for images with large extended objects on the image, the background was introducing large depressions of negative pixels and we turned background estimation on those.

The reference images were taken a posteriori a few months after the alert, on December 2015, using the same telescope in Bosque Alegre.
The reference images were taken with about the same exposure time for all fields and the same binning.
The references images were aligned pixel to pixel to the science images with the software Astroalign (see section \ref{astroalign_section} for more details on this Python module).


\section{Real-Bogus classification and detection of potential transients}

Once aligned we perform the same procedure as with the CSTAR image set.
We erase stars on the reference images to create fictitious transients after a subtraction is made.
We perform the subtraction using the Python module OIS (see section \ref{ois_section}).
Some of the tiles have to be 

Once the subtraction is done, we pass SExtractor on the subtraction image to recover these fabricated transients and their associated SExtractor parameters.
One difference with the procedure done with CSTAR is that we do not separate sources into bins of flux, because we have relatively much fewer stars in the field.

For each transient we generate this way we add an equal amount of subtraction bogus artifact, to keep the training set balanced in number.
We worked with 1511 examples of `real' transients and 1511 examples of `bogus' subtraction artifacts
taken from tiles 13, 14, 16, 17, 18, 19 and 20 (see table \ref{o1targets}).
With these we trained a classifier.

The classifier had very good score statistics, but not as good as the one with CSTAR, most likely because of the lower sampling of `transient' examples.
Nonetheless all performance statistics score above 90\%. 

The particular Random Forest algorithm we used is the one provided in {\em scikit-learn} (\citet{2012arXiv1201.0490P}), a popular Python package for Machine Learning analysis.
We have 10 Decision Trees in the ensemble, each one with a `Gini impurity' criterion to decide on the split of the branches.
Each tree decides based on the square root of the number of features. On our case, with the features in table \ref{mlfeatures}, 
the algorithm will branch its decisions based on 4 features randomly chosen.

% self, n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None

Several scores of the training are given on table \ref{gwscores} including the confusion matrix of the training.
The receiver operating characteristic (ROC) curve is presented in figure \ref{fig:roc_gw150914}.

\begin{comment}
\begin{table}
\centering
\begin{tabular}{ l|c|c| }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{real}
 & \multicolumn{1}{c}{bogus} \\
\cline{2-3}
{\it Classified as} real & 1390 & 121 \\
\cline{2-3}
{\it Classified as} bogus & 144 & 1367 \\
\cline{2-3}
\end{tabular}
\caption{Confusion Matrix}
\label{gwconfusionmatrix}
\end{table}
\end{comment}

\begin{table}
\centering
\begin{tabular}{| >{\itshape}l | l |}
  \hline
  accuracy & 0.9123 \\ \hline
  precision & 0.9186 \\ \hline
  recall & 0.9046 \\ \hline
  F measure & 0.9116 \\ \hline
  Confusion Matrix & \begin{tabular}{ l|c|c| }
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{real}
 & \multicolumn{1}{c}{bogus} \\
\cline{2-3}
{\it Classified as} real & 1390 & 121 \\
\cline{2-3}
{\it Classified as} bogus & 144 & 1367 \\
\cline{2-3}
\end{tabular} \\ \hline
\end{tabular}
\caption{Random Forest Scores}
\label{gwscores}
\end{table}

Applying this Real-Bogus classifier on subtraction images for that day, resulted in zero potential transient candidates in all images 
with probability of being real over 90\%, and only 40 above 80\%.
There were 226 potential candidates with probability over 50\%.
As a final discrimination against spurious detections, we required an object to be detected in at least 5 of 10 realizations
of a given field in order to be considered a bona fide astrophysical transient. 
None of the objects in either set passed this requirement. 
Further visual inspection revealed most of them to be subtraction residuals or cosmetic defects in the detector. 
We therefore conclude that no transients were present in the 21 fields we targeted, to a 5$\sigma$ limiting magnitude of r = 21.7.

\begin{figure}
\centering
\includegraphics[scale=0.6]{figures/roc_gw150914}
\caption{The ROC curve for the Random Forest classifier trained with transients generated from the images.}
\label{fig:roc_gw150914}
\end{figure}


No bona fide events were found, a result that is consistent with the low probability of detecting stellar or extragalactic variability 
given our temporal and areal coverage, and with the later classification of the GW event as a merger of two stellar-mass black holes.

\section{Results}

The fact that we did not find any genuine transient in our search is not surprising given the small area surveyed (\textasciitilde{}0.62 sq. degrees) 
and the low cadence of the observations (with only two epochs per target, separated by 73$\pm$3d). 
Based on our temporal sampling and photometric precision, we scaled the results of Oelkers et al. (2015, 2016) 
to estimate that only 1 in \textasciitilde{}3,030 stars in our fields
would exhibit variability detectable at the 5$\sigma$ level over this timescale. 
Given that only 4,200 stars were detected across all fields by DAOPHOT, we would only expect to detect \textasciitilde{}1 variable star.
Regarding extragalactic transients, based on supernova Ia rate for R < 21 mag of 10 events per square degree per year
(Pain et al. 1996; Garnavich et al. 2004) and a 30\% fraction of SN Ia among local SNe (Guillochon et al. 2016), 
we estimate an 11\% probability of finding such an object across all our fields. 
Finally, our result is consistent with the LIGO detection of a binary black hole merger, for which no optical EM counterpart is expected.


\chapter{Software Developed}
\section{Pipeline}

Since the ultimate goal of the TOROS Project is the robotization of the telescope,
it is important to have in place a software `pipeline' that accompanies the process
at all stages, from receiving the alert to propose new transient candidates.

The whole operation of TOROS processing can be divided in several stages (Tania ref)
as pictured in figure ??.

The first stage consists on ...

\subsection{Alert Receiver Robot}

The first step of the process starts with the alert receiver robot.

The alert receiver is hosted in a virtual machine server provided by UTRGV IT Services.
It is a Python script that runs uninterruptedly waiting for a signal from the 
GCN service of NASA delivered on a specific port reserved for this purpose.

The Gamma-Ray burst Coordinates Network (GCN) and the Transient Astronomy Network (TAN), collectively called the GCN/TAN network,
is a distribution network of transient events notices dependent on Goddard NASA.
As its name suggest it was primarily intended for the distribution of GRBs but also other transient notices
from Fermi and Swift spacecrafts to the rest of the Astronomy community. 
Most notices are sent in real-time, while the event is still ongoing, 
others are delayed due to telemetry down-link delays.

The subsequent reports of follow-up observations made by ground-based observers, are done by submitting circulars to that same site.
This makes the GCN/TAN network ``a one-stop shopping network for follow-up sites and GRB and transient researchers.''

The LIGO-Virgo Collaboration makes use of the GCN network to disseminate the event
notices to the participating observatories searching for EM counterparts.

The notice comes in the form of a Virtual Observatory Event (VOE) file,
and it is distributed as a message to predefined static IPs and ports,
using the VOEvent Transport Protocol.

\textcolor{blue}{VOEvent is an IVOA Recommendation -- that is, it has been adopted as an international standard. As with many other IVOA standards, VOEvent is based on XML, the Extensible Markup Language [9]. XML is ubiquitous in worldwide web technologies and simply provides a structured way to build a nested hierarchy of elements, to attach attributes to those elements, and to assign values to each. An additional constraint on many IVOA standards, including VOEvent, is a schema to apply rules on the arrangement and numbers of each element and attribute and on their allowed values. XML Schema [10] can be an often-entertaining technology for the designers of a standard. Providing a battle-hardened VOEvent schema [11] is a priority of the VOEvent v2.0 development effort. A well-crafted schema permits the validation of documents (in this case VOEvent messages, also referred to as ``packets'') against the requirements of the standard, and can even be used to automatically create software to parse such messages.}

The VOEvent Transport Protocol is a simple TCP-based protocol for transporting VOEvent messages from authors, through brokers, to subscribers.

VOEvent is the International Virtual Observatory Alliance (IVOA) recommended mechanism for describing astronomical transients.
According to its main website \footnote{\href{http://wiki.ivoa.net/twiki/bin/view/IVOA/IvoaVOEvent}{http://wiki.ivoa.net/twiki/bin/view/IVOA/IvoaVOEvent}},
it is an XML file notice that ``{\em defines the content and meaning of a standard information packet for representing, transmitting, publishing and archiving information about a transient celestial event, with the implication that timely follow-up is of interest.}'' 

In our case, we registered two static IPs with GCN, one in Texas at UT RGV and another one for Cordoba in Argentina at IATE Institute.
Only the one in Texas is functional at the moment, while the one in Cordoba is receiving but has problems sending out emails.

The VOEvent is received by a continuously running script that listens on the specific port and creates an alert email involving the heads and some staff at each TOROS partner.

The listening is done mainly by the PyGCN module developed by Leo Singer, which handles the reception GCN notices from LVC. The rest of email sending is done by usual Python tools for that task.

Right now, the script does a minimum process to deliver the XML body of the VOEvent by email to predetermined recipients.
Future improvements on this side should include the automatic download of the skymaps
to be attached to the email along with the VO Event notice.

It could also pre-process the skymap to extract most likely galaxy hosts for observing targets.

Right now, this is done on a separate script that requires human intervention.

\subsection{Target Selection}

As mentioned before, the target selection is done with a separate script.
This script makes use of the sky-map provided in the alert notice and the 
Gravitational Waves Galaxy Catalog (GWGGC) (A List of Galaxies for Gravitational Wave Searches, Darren J. White et al, 2011)

The White's catalog is a homogeneous list of 53,255 galaxies within 100Mpc.
It is a compilation from 4 different catalogs: an updated version of the Tully Nearby Galaxy Catalog,
the Catalog of Neighboring Galaxies, the V8k catalogue and HyperLEDA.

GWGC contains information on sky position, distance, blue magnitude, major and minor diameters, position angle, and galaxy type.
Also included in the catalog are 150 Milky Way globular clusters.

The authors claim (ref) that GWGC is more complete --within 100 Mpc-- than other catalogs,
due to their use of more up-to-date input catalogs
and the fact that they don't make a blue luminosity cut.

Another catalog along these lines is the Glade GW Catalog. Glade Catalog has xxxx galaxies listed, this many more than CWGC and extends up to XX Mpc.
Nonetheless many distances are inferred by Machine Learning Methods, and completitude of the Catalog... bla bla

The target selection is based on two main criteria: the localization (un)certainty on the target pixel in the all-sky map given by LIGO at the time of the alert,
and several filter cuts on distance, blue luminosity and apparent magnitude.

This marriage between GW and Optical parameters of observability ensures the targets are visible at each telescope site, and that they have some significant probability of being the host.
The list of filter cuts are summarized in table \ref{obsfilters}.

\begin{table}
\centering
\begin{tabular}{|l|c|}
  \hline
 Parameter & Limit value \\ \hline
Observability from location & $30^{\circ} > \delta > -70^{\circ}$ for EABA \\ \hline
Apparent Magnitude & $B \le 21$ mag \\ \hline
Distance  & $D < 60$ Mpc \\ \hline
Absolute Magnitude & $MB \le -21$ mag \\ \hline
\end{tabular}
\caption{Parameter Cuts}
\label{obsfilters}
\end{table}

\subsection{The Broker}

Once the list of targets is done, we need to communicate the targets to each telescope.
This is done through a broker website written in Django.
Each telescope representative has assigned a username and password to access a website hosted on UTRGV servers.
This website has a simple interface of tables for each observatory and a list of targets observable from each location, obtained by the target selection method on the previous step.

Each telescope admin then selects targets from the list, to reserve them for his or her observatory. 
The website enforces that the list of targets be unique and that no two observatories are observing the same target.
It does so, by ignoring targets previously selected by others on the query.

Each observatory then carries the observations for the successive nights and file a report of the observations when these are done.

The website can also output a circular draft of all the targets observed by each telescope to be submitted to the GCN/TAN website for the rest of the community.

\subsection{Corral Pipeline Framework}

As part of the 

\subsection{Further Processing}

The previous steps are the normal workflow for the operations on a LIGO campaign.

The pipeline is not fully automatized or optimized for all of the stages, and there are still gaps where human intervention is needed.
Most notably is the target selction or scheduling, and the loading of the observation targets to the broker website.
Making them automatic, would require a REST framework on the Django website and a transfer protocol mechanism,
which are beyond the computational abilities of who writes this thesis.
It is my hope that the software developed so far could be picked up by a web developer that can connect the parts in a seamless way.

The pipeline is written entirely in Python, following the latest trend in Astronomy.
For the web pages developed to support the collaboration, we used the popular Python web framework Django
and a light database on Sqlite 3.

Sqlite provides a lightweight database solution that does not require complex server-client operations, and it stores all data in a simple file.
Thus, the database is easy to browse and modify.
The database handles information for the GW Galaxy Catalog, the user information as well as permissions and login information,
Observatories data.

The following stages of the pipeline deal with the specific analysis to identify candidates to optical counterparts of GW.

The first part deals with the Difference Image Analysis.
For that two images, one taken at the epoch of interest and another one used as a reference. Ideally, the reference is an archive image or a stack of several others to improve signal to noise ratio, cosmic rays and other contaminants on the image.

In the case for our campaign for O1, we had to use a-posteriori references taken a few months after the event.

Before performing the subtraction, both images have to be aligned pixel by pixel.
Software to perform the alignments was done using a method described in section \ref{astroalign_section}.
I describe there a method based on asterism matching inspired in astrometry.net.

The subtraction methods are explained in section \ref{ois_section}.
Several algorithms are explained in the literature with a wide range of methods, from Fourier Transform, to PSF matching to using Information Theory.
Some of them are explained and implemented in a Python module named `ois' developed by me for this project.

\include{chapter_astroalign/chapter} \label{astroalign_section}

\section{OIS Python Package} \label{ois_section}
	
OIS (Optimal Image Subtraction) is a Python module that implements several Difference Image Analysis methods as described in section X.

It works on Numpy arrays, so that way is agnostic on the origin of the image. 

Bad pixels that need to be ignored in the image are marked using Numpy's masked arrays (True on bad pixel).

The interface to the user has two entry points: the module methods optimal\_system and subtract\_on\_grid. The latter is just a convenient method to partition the image in a certain grid and perform the former on each grid, taking into account pixels outside the grid when necessary.

optimal\_system will return ...

OIS has documentation on the popular documentation site readthedocs.io.
OIS is released under MIT Licence and has a GitHub page on ...

\section{Winnow - Human classification of Real/Bogus}

Blue is from Hotwiring the Transient Universe:

\textcolor{blue}{While machines are capable of many types of information processing, they are not so good where something new is present that has not been programmed. Certainly we expect the future flood of events to be mostly handled by machines, with the uninteresting ones never seen by a human expert, but some may be escalated in importance and come to the attention of such experts through a message, or even being urgently awoken in the night.}

\textcolor{blue}{There could be a large number of other people also involved in the enterprise, volunteers recruited from the internet, with some, but by no means expert, ability. All people have excellent image analysis capabilities: they could, for example, look at an image of a star field and determine quickly and accurately if there is an artifact, such as a satellite trail, interference from a nearby bright star, or one of many Earthbound artifacts: from the telescope, camera, or electronics. While many of these types of common artifacts can be detected by machine, there are always new types, or artifacts that are a combination of known types. Since the transient detection software is looking for differences between new and past observations, such artifacts, though rare, will be inevitably found and thus pollute the event stream.}

\textcolor{blue}{This type of `citizen science' has been both popular and extremely useful in GalaxyZoo[6] and CitizenSky[7], and we expect it to be the same with events. A new aspect with events, different from the traditional web-based citizen science, could be that events are `pushed' to the volunteers, so they can respond with their mobile device immediately. Another novel aspect to citizen science could be the recruiting of a cadre of dedicated volunteers to work at a more expert level, looking at light curves or other non-image data; they would need to be sufficiently motivated to study and take a test, to be inducted to this higher level.}

\textcolor{blue}{Given that there will be tens of thousands of transient candidates competing for scarce resources, it is impossible to eyeball even those that survive the myriad of classification steps mentioned earlier. Human neural networks can come to the rescue in such a case. Details about citizen science are provided elsewhere in this book. Here we would like to highlight one particular aspect, the synergy between machine learning and human pattern recognition expertise to improve the machine learning methodologies.}

It is worth mentioning that the web server also hosts a related project `winnow', a web interface to manually classify potential transients
on subtraction images, by voting on `real' or `bogus' categories. 
This voting allows to have good training sets to later train automatic classifiers to do the same task.
The website was tested successfully with many undergraduate and graduate students, 
and there are plans to apply it to high-school students as a way of citizen science project.

    
\chapter{Conclusions}
* The future of LIGO, TOROS and multi messenger astronomy


\appendix

\chapter{Derivation of the Gravitational Wave Equations} \label{gwderivation}

Gravitational waves are a particular kind of solution to the Einstein's field equations of General Relativity.

In many situations we can consider, we are in a flat background situation, in which our metric does not differ much locally from the Minkowski metric.
Suppose we are far away, removed from any strong source in an asymptotically flat spacetime.

In such situation we can assume that locally our metric is the Minkowski metric $\eta$ plus some small deviation $h$. We want to study the dynamics of such small perturbation in a linearized Einstein field equation. 


To do that, we consider the metric $g = \eta + h$ in the linearized Einstein's field equations. Linearized here means that quadratic and higher factors of $h$ will be simply ignored, as they are assumed much smaller than the flat metric.

Let's find out what condition the Einstein field equation $G_{\mu \nu}(\eta + h) = 8\pi T_{\mu \nu} = 0$ imposes on this small perturbation $h$.

%\begin{align}
%G_{\mu \nu}(\eta + h) = 8\pi T_{\mu \nu} = 0
%\end{align}

%It is worth noting here that Einstein equations are not linear in nature, but they are second order on the metric derivatives and furthermore linear on the second order terms. This will allow us to derive from the linearized Einstein equations, a second order wave equation on the small perturbation $h$ that decouples from $\eta$.

%Another issue to point out is that the vague definition of 'small perturbation' has to be of physical nature and not an artifact on the choice of the coordinate system. We will not worry about this issue on the present work, but it is worth keeping it in mind. Other concerns about coordinate system effects were historically raised and settled in time, particularly the many gauge choices done during the derivation.

The Christoffel symbols to first order in $h$ are:

\begin{align}
\Gamma_{abc} &= \frac{1}{2} \left( g_{ca,b} + g_{cb,a} - g_{ab,c} \right) \\
  &= \frac{1}{2} \left( (\eta + h)_{ca,b} + (\eta + h)_{cb,a} - (\eta + h)_{ab,c} \right) \\
 &=\frac{1}{2} \left( h_{ca,b} + h_{cb,a} - h_{ab,c} \right) 
\end{align}

At this point we must note that we will still call $g^{ab}$ the inverse of $g_{ab}$, which is $g^{ab} = \eta^{ab} - h^{ab}$ to first order in $h$. 

And thus,
\begin{align}
\Gamma^{a}_{bc} &= g^{cd} \Gamma_{abd} \\
 &=(\eta - h)^{cd} \Gamma_{abd} \\
 &= \frac{1}{2} \eta^{cd} \left( h_{ca,b} + h_{cb,a} - h_{ab,c} \right) + \order(h^2)
\end{align}

Similarly, the Ricci tensor to first order in $h$ will be:

\begin{align}
R_{ab} &= \Gamma^{c}_{ab,c} - \Gamma^{c}_{cb,a} \\
&= \frac{1}{2} \left( h_{a}{}^{c}{}_{,bc} + h_{b}{}^{c}{}_{,ac} - h_{ab,c}{}^{c} - h_{c}{}^{c}{}_{,ab} \right)
\end{align}

Which will finally lead us to the Einstein's tensor $G$:

\begin{align}
G_{ab} &= R_{ab} - \frac{1}{2}g_{ab}R \\
&= R_{ab} - \frac{1}{2}\eta_{ab}R + \order(h^2) \\
&= \frac{1}{2} \left( h_{ac,b}{}^{c} + h_{bc,a}{}^{c} - h_{ab,c}{}^{c} - h_{c}{}^{c}{}_{,ab} -\eta_{ab} \left( h_{cd,}{}^{cd} - h_{c}{}^{c}{}_{,d}{}^{d} \right) \right)
\end{align}

This can be brought to a shorter form defining $\bar{h}{}_{ab} = h_{ab} - \eta_{ab} h$

Where $h = h_{c}{}^{c}$ is the trace of the metric tensor $h$.
With this definition, the Einstein's field equation becomes:

\begin{align}
\bar{h}{}_{ab,c}{}^{c} + \bar{h}{}_{ac,b}{}^{c} + \bar{h}{}_{bc,a}{}^{c} -\eta_{ab} \bar{h}{}_{cd,}{}^{cd} = 0
\end{align}

\section{Gauge choices}

There is a gauge freedom in General Relativity corresponding to the group of diffeomorphisms, that can be used to simplify the equations even more. Just like the Gauge freedom in electrodynamics $A \rightarrow A + \partial \chi$ we can chose $h$ to satisfy $\bar{h}{}_{ab,}{}^{b} = 0$

In this ``Lorentz Gauge'', the linearized Einstein field equations, reduce to the usual wave equation for each component of $\bar{h}$:

\begin{align}
\bar{h}_{ab,c}{}^{c} = \Box{\bar{h}{}_{ab}} = 0
\end{align}

Further gauge choices can let us choose the trace of $\bar{h}$ to be zero and each $h_{0\mu}$ component to be zero for $\mu = 0,1,2,3$. Notice that once the trace of $\bar{h}$ is set to zero, it implies that $\bar{h}{}_{ab} = h_{ab}$

\begin{align} \label{gaugecond}
& \Box{h_{ab}} = 0 \\
& h_{ab,}{}^{b} = 0 \\
& h_{a}{}^{a} = 0 \\
& h_{0 \mu} = 0; \; \mu=0,1,2,3
\end{align}

This is called the transverse traceless (TT) gauge. The reader can refer the full derivation for the gauge choices in Misner or Wald.

With the conditions in (\ref{gaugecond}), we seek solutions in the form of plane waves of the form $h_{ab} = H_{ab}e^{\pm \imath k_{\mu}x^{\mu}}$.

Our gauge conditions impose similar conditions on $k$ and $H$:

\begin{align}
& k^{\mu} H_{\mu \nu} = 0 \\
& H_{\mu}{}^{\mu} = 0 \\
& H_{0 \mu} = 0; \; \mu=0,1,2,3
\end{align}

This leaves $H$ with only two independent components. If we consider a wave propagating in the z direction, the most general form for a transverse traceless metric will be:

\begin{equation}
\begin{bmatrix}
0 & 0 & 0 & 0 \\
0 & h_{+} & h_{\times} & 0 \\
0 & h_{\times} & -h_{+} & 0 \\
0 & 0 & 0 & 0 \\
\end{bmatrix}
e^{\pm \imath k_{\mu}x^{\mu}}
\end{equation}

and the total metric $g$

\begin{equation}
\begin{bmatrix}
-1 & 0 & 0 & 0 \\
0 & 1 + h_{+}e^{\pm \imath k_{\mu}x^{\mu}} & h_{\times} e^{\pm \imath k_{\mu}x^{\mu}} & 0 \\
0 & h_{\times} e^{\pm \imath k_{\mu}x^{\mu}} & 1 - h_{+}e^{\pm \imath k_{\mu}x^{\mu}} & 0 \\
0 & 0 & 0 & 1 \\
\end{bmatrix}
\end{equation}

The two independent polarizations are called ``h plus'' ($h_+$) and ``h cross'' ($h_{\times}$).

\include{chapter_DIA/chapter}

\chapter{Notations}

Here we show the use of multiple appendixes.

\section{Math Notations}

Each appendix can have sub-sections as a regular chapter.

\section{Additional Notations}

\pagebreak{}

\bibliographystyle{aa}
% was: \bibliographystyle{plain}
\nocite{*}
\bibliography{mybiblio}

\begin{vita}
\section*{Education}

\begin{itemize}
  \item B.S. Physics, National Cordoba University (Argentina), 2007.
  \item M.S. Physics, University of Texas at Brownsville, 2010.
\end{itemize}

\section*{Publications}

\begin{itemize}
\item \href{https://arxiv.org/abs/1701.05566}{\bf Corral Framework: Trustworthy and Fully Functional Data Intensive Parallel Astronomical Pipelines} (2017) Juan B. Cabral, Bruno Snchez, Martn Beroiz, Mariano Domnguez, Marcelo Lares, Sebastin Gurovich, Pablo Granitto; {\it submitted to Astronomy and Computing}.
\item \href{http://adsabs.harvard.edu/abs/2016ApJ...828L..16D}{\bf GW150914: First search for the electromagnetic counterpart of a gravitational-wave event by the TOROS collaboration} (2016). Mario C. Diaz et al; {\it The Astrophysical Journal Letters}, Volume 828, Issue 2, article id. L16, 6 pp.
\item \href{http://adsabs.harvard.edu/abs/2016ApJ...826L..13A}{\bf Localization and broadband follow-up of the gravitational-wave transient GW150914} (2016). B. P. Abbott et al. {\it The Astrophysical Journal Letters}, Volume 826, Issue 1, article id. L13, pp
\item \href{http://www.math.unm.edu/~lau/DMS1216866/tauFluids_BHLP.pdf}{\bf Multidomain, sparse, spectral-tau method for helically symmetric flow} (2014). M Beroiz, T Hagstrom, SR Lau, RH Price; {\it Computers and Fluids}  (2014), pp. 250-265.
\item \href{http://iopscience.iop.org/1538-3881/147/5/100}{\bf Bright microwave pulses from PSR B0531+21 observed with a prototype transient survey receiver} April 2014. J. Andrew O'Dea, F. A. Jenet, Tsan-Huei Cheng, Chau M. Buu, Martin Beroiz, Sami W. Asmar, and J. W. Armstrong; {\it Astronomical Journal}, 147, 100.
\item \href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5555950}{\bf A Prototype Radio Transient Survey Instrument for Piggyback Deep Space Network Tracking}, May 2011. Chau M. Buu, Fredrick A. Jenet, John W. Armstrong, Sami W. Asmar, Martin Beroiz, Tsan-Huei Cheng, and J. Andrew O'Dea; {\it Proceedings of the IEEE} Volume 99, Number 5.
\item \href{http://journals.aps.org/prd/abstract/10.1103/PhysRevD.76.024012}{\bf Gravitational instability of static spherically symmetric Einstein-Gauss-Bonnet black holes in five and six dimensions}, 2007. M. Beroiz, G. Dotti y R.J. Gleiser, {\it Physical Review D} 76, 024012 hep-th/0703074.
\end{itemize}


\section*{Scientific Meetings and Conferences}

\begin{itemize}
\item \href{http://adsabs.harvard.edu/abs/2016APS..APRR14005B}{Speaker at the APS April Meeting 2016}, abstract R14.005. "Results of optical follow-up observations of advanced LIGO triggers from O1 in the southern hemisphere". South Lake City, April 2016.
\item \href{https://conference.scipy.org/scipy2014/schedule/presentation/1730/}{SciPy Conference 2014. Speaker at Mini Symposium in Astronomy}. "Transient detection and image analysis pipeline for TOROS project". Austin July 2014.
\item Advances and Challenges in Computational General Relativity, Brown University, Providence, RI, May 20-22, 2011.
\item Poster presentation 215th American Astronomical Society (AAS) Meeting, Washington DC, January 3-7, 2010 ``The X-ray Emission of SN1978K: Still Here After All These Years''  - Eric M. Schlegel, M. Beroiz.
\item Poster presentation 215th American Astronomical Society (AAS) Meeting, Washington DC, January 3-7, 2010 ``Current Results at PALFA Pulsar Survey at Arecibo Observatory'' - M. Beroiz, K. Stovall, F. Jenet, J. Cordes, D. Lorimer, D. Backer, PALFALFA Consortium.
\item Summer Provost Research Program at UTSA, 2009. Research on X-ray spectrum of Super Nova 1978K and Poster Presentation.
\item UTB Summer School in Gravitational Wave Astronomy at South Padre Island TX, June 2008.
\item Grav07, La Falda (Cordoba), Argentina. November 5-7, 2007.
\item Poster Presentation at 92nd AFA (Physics Association Argentina) Annual Meeting, Salta, Argentina, September 24-27, 2007.
\end{itemize}

\end{vita}

\end{document}
